{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "import os\n",
    "import re\n",
    "from typing import List, Callable, Union, Dict\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # ì´ ì¤„ì„ ì¶”ê°€í•˜ì—¬ F.interpolate ì‚¬ìš© ì—ëŸ¬ í•´ê²°\n",
    "import torch.optim as optim\n",
    "from torch.cuda import amp\n",
    "\n",
    "# Pytorch Quantization\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "from pytorch_quantization.nn.modules import _utils as quant_nn_utils\n",
    "from pytorch_quantization import calib\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "from pytorch_quantization import quant_modules\n",
    "from pytorch_quantization import tensor_quant\n",
    "from absl import logging as quant_logging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantAdd(torch.nn.Module):\n",
    "    def __init__(self, quantization):\n",
    "        super().__init__()\n",
    "        if quantization:\n",
    "            self._input0_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "            self._input1_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "        self.quantization = quantization\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        if self.quantization:\n",
    "            # print(f\"QAdd {self._input0_quantizer}  {self._input1_quantizer}\")\n",
    "            return self._input0_quantizer(x) + self._input1_quantizer(y)\n",
    "        return x + y\n",
    "\n",
    "class QuantC2fChunk(torch.nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self._input0_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "        self.c = c\n",
    "    def forward(self, x, chunks, dims):\n",
    "        return torch.split(self._input0_quantizer(x), (self.c, self.c), dims)\n",
    "\n",
    "class QuantConcat(torch.nn.Module): \n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self._input0_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "        self._input1_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x, dim):\n",
    "        x_0 = self._input0_quantizer(x[0])\n",
    "        x_1 = self._input1_quantizer(x[1])\n",
    "        return torch.cat((x_0, x_1), self.dim) \n",
    "\n",
    "class QuantUpsample(torch.nn.Module): \n",
    "    def __init__(self, size, scale_factor, mode):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self._input_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.interpolate(self._input_quantizer(x), self.size, self.scale_factor, self.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (addop): QuantAdd(\n",
       "              (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (addop): QuantAdd(\n",
       "              (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (addop): QuantAdd(\n",
       "              (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (addop): QuantAdd(\n",
       "              (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(\n",
       "        scale_factor=2.0, mode='nearest'\n",
       "        (upsampleop): QuantUpsample(\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (11): Concat(\n",
       "        (concatop): QuantConcat(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(\n",
       "        scale_factor=2.0, mode='nearest'\n",
       "        (upsampleop): QuantUpsample(\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (14): Concat(\n",
       "        (concatop): QuantConcat(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat(\n",
       "        (concatop): QuantConcat(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat(\n",
       "        (concatop): QuantConcat(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (22): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a model\n",
    "from ultralytics import YOLO\n",
    "# model = YOLO(\"yolov8n_.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"yolov8n_relu_int8.pt\")  # load a pretrained model (recommended for training)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def bottleneck_quant_forward(self, x):\n",
    "        if hasattr(self, \"addop\"):\n",
    "            return self.addop(x, self.cv2(self.cv1(x))) if self.add else self.cv2(self.cv1(x))\n",
    "        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
    "\n",
    "    def concat_quant_forward(self, x):\n",
    "        if hasattr(self, \"concatop\"):\n",
    "            return self.concatop(x, self.d)\n",
    "        return torch.cat(x, self.d)\n",
    "\n",
    "    def upsample_quant_forward(self, x):\n",
    "        if hasattr(self, \"upsampleop\"):\n",
    "            return self.upsampleop(x)\n",
    "        return F.interpolate(x)\n",
    "\n",
    "    def c2f_qaunt_forward(self, x):\n",
    "        if hasattr(self, \"c2fchunkop\"):\n",
    "            y = list(self.c2fchunkop(self.cv1(x), 2, 1))\n",
    "            y.extend(m(y[-1]) for m in self.m)\n",
    "            return self.cv2(torch.cat(y, 1))\n",
    "            \n",
    "        else:\n",
    "            y = list(self.cv1(x).split((self.c, self.c), 1))\n",
    "            y.extend(m(y[-1]) for m in self.m)\n",
    "            return self.cv2(torch.cat(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add C2fQuantChunk to model.model.2\n",
      "Add QuantAdd to model.model.2.m.0\n",
      "Add C2fQuantChunk to model.model.4\n",
      "Add QuantAdd to model.model.4.m.0\n",
      "Add QuantAdd to model.model.4.m.1\n",
      "Add C2fQuantChunk to model.model.6\n",
      "Add QuantAdd to model.model.6.m.0\n",
      "Add QuantAdd to model.model.6.m.1\n",
      "Add C2fQuantChunk to model.model.8\n",
      "Add QuantAdd to model.model.8.m.0\n",
      "Add QuantUpsample to model.model.10\n",
      "Add QuantConcat to model.model.11\n",
      "Add C2fQuantChunk to model.model.12\n",
      "Add QuantUpsample to model.model.13\n",
      "Add QuantConcat to model.model.14\n",
      "Add C2fQuantChunk to model.model.15\n",
      "Add QuantConcat to model.model.17\n",
      "Add C2fQuantChunk to model.model.18\n",
      "Add QuantConcat to model.model.20\n",
      "Add C2fQuantChunk to model.model.21\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if module.__class__.__name__ == \"C2f\":\n",
    "        if not hasattr(module, \"c2fchunkop\"):\n",
    "            print(f\"Add C2fQuantChunk to {name}\")\n",
    "            module.c2fchunkop = QuantC2fChunk(module.c)\n",
    "        module.__class__.forward = c2f_qaunt_forward\n",
    "\n",
    "    if module.__class__.__name__ == \"Bottleneck\":\n",
    "        if module.add:\n",
    "            if not hasattr(module, \"addop\"):\n",
    "                print(f\"Add QuantAdd to {name}\")\n",
    "                module.addop = QuantAdd(module.add)\n",
    "            module.__class__.forward = bottleneck_quant_forward\n",
    "            \n",
    "    if module.__class__.__name__ == \"Concat\":\n",
    "        if not hasattr(module, \"concatop\"):\n",
    "            print(f\"Add QuantConcat to {name}\")\n",
    "            module.concatop = QuantConcat(module.d)\n",
    "        module.__class__.forward = concat_quant_forward\n",
    "\n",
    "    if module.__class__.__name__ == \"Upsample\":\n",
    "        if not hasattr(module, \"upsampleop\"):\n",
    "            print(f\"Add QuantUpsample to {name}\")\n",
    "            module.upsampleop = QuantUpsample(module.size, module.scale_factor, module.mode)\n",
    "        module.__class__.forward = upsample_quant_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('yolov8n_relu_int8.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8_relu summary (fused): 218 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n_relu_int8.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (18.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.8s, saved as 'yolov8n_relu_int8.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (1.5s)\n",
      "Results saved to \u001b[1m/works/ultralytics\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n_relu_int8.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n_relu_int8.onnx imgsz=640 data=/works/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "WARNING âš ï¸ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Loading yolov8n_relu_int8.onnx for ONNX Runtime inference...\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /works/ultralytics/bus.jpg: 640x640 4 persons, 1 bus, 37.1ms\n",
      "Speed: 3.0ms preprocess, 37.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "model.export(format='onnx')  # creates 'yolov8s.onnx'\n",
    "\n",
    "# Load the exported ONNX model\n",
    "onnx_model = YOLO('yolov8n_relu_int8.onnx')\n",
    "\n",
    "# Run inference\n",
    "results = onnx_model('https://ultralytics.com/images/bus.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from cache: /usr/src/datasets/coco/labels/train2017.cache\n",
      "cal_model\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n_relu.pt, data=/works/ultralytics/ultralytics/cfg/datasets/coco.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train20, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/usr/src/ultralytics/runs/detect/train20\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='n'.\n",
      "\u001b[34m\u001b[1mactivation:\u001b[0m nn.ReLU()\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "either size or scale_factor should be defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 100\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcal_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[39m# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•¨ìˆ˜ ì‹¤í–‰\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m cal_model(model, train_loader, device)\n",
      "Cell \u001b[0;32mIn[37], line 59\u001b[0m, in \u001b[0;36mcal_model\u001b[0;34m(model, data_loader, device, num_batch)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m                 module\u001b[39m.\u001b[39menable()\n\u001b[0;32m---> 59\u001b[0m collect_stats(model, data_loader, device, num_batch\u001b[39m=\u001b[39;49mnum_batch)\n\u001b[1;32m     60\u001b[0m compute_amax(model, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[37], line 31\u001b[0m, in \u001b[0;36mcal_model.<locals>.collect_stats\u001b[0;34m(model, data_loader, device, num_batch)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Feed data to the network and collect statistics\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# Enable calibrators\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m model\u001b[39m.\u001b[39;49meval()\n\u001b[1;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m name, module \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mnamed_modules():\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(module, quant_nn\u001b[39m.\u001b[39mTensorQuantizer):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2449\u001b[0m, in \u001b[0;36mModule.eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m: T) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m   2434\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Set the module in evaluation mode.\u001b[39;00m\n\u001b[1;32m   2435\u001b[0m \n\u001b[1;32m   2436\u001b[0m \u001b[39m    This has any effect only on certain modules. See documentations of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m   2448\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/engine/model.py:657\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m (trainer \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_smart_load(\u001b[39m\"\u001b[39m\u001b[39mtrainer\u001b[39m\u001b[39m\"\u001b[39m))(overrides\u001b[39m=\u001b[39margs, _callbacks\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks)\n\u001b[1;32m    656\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mresume\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mget_model(weights\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, cfg\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49myaml)\n\u001b[1;32m    658\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[1;32m    660\u001b[0m     \u001b[39mif\u001b[39;00m SETTINGS[\u001b[39m\"\u001b[39m\u001b[39mhub\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession:\n\u001b[1;32m    661\u001b[0m         \u001b[39m# Create a model in HUB\u001b[39;00m\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/models/yolo/detect/train.py:88\u001b[0m, in \u001b[0;36mDetectionTrainer.get_model\u001b[0;34m(self, cfg, weights, verbose)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_model\u001b[39m(\u001b[39mself\u001b[39m, cfg\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, weights\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     87\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a YOLO detection model.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     model \u001b[39m=\u001b[39m DetectionModel(cfg, nc\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[\u001b[39m\"\u001b[39;49m\u001b[39mnc\u001b[39;49m\u001b[39m\"\u001b[39;49m], verbose\u001b[39m=\u001b[39;49mverbose \u001b[39mand\u001b[39;49;00m RANK \u001b[39m==\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     89\u001b[0m     \u001b[39mif\u001b[39;00m weights:\n\u001b[1;32m     90\u001b[0m         model\u001b[39m.\u001b[39mload(weights)\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/nn/tasks.py:297\u001b[0m, in \u001b[0;36mDetectionModel.__init__\u001b[0;34m(self, cfg, ch, nc, verbose)\u001b[0m\n\u001b[1;32m    295\u001b[0m m\u001b[39m.\u001b[39minplace \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minplace\n\u001b[1;32m    296\u001b[0m forward \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(x)[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(m, (Segment, Pose, OBB)) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(x)\n\u001b[0;32m--> 297\u001b[0m m\u001b[39m.\u001b[39mstride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([s \u001b[39m/\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m forward(torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m, ch, s, s))])  \u001b[39m# forward\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mstride\n\u001b[1;32m    299\u001b[0m m\u001b[39m.\u001b[39mbias_init()  \u001b[39m# only run once\u001b[39;00m\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/nn/tasks.py:296\u001b[0m, in \u001b[0;36mDetectionModel.__init__.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    294\u001b[0m s \u001b[39m=\u001b[39m \u001b[39m256\u001b[39m  \u001b[39m# 2x min stride\u001b[39;00m\n\u001b[1;32m    295\u001b[0m m\u001b[39m.\u001b[39minplace \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minplace\n\u001b[0;32m--> 296\u001b[0m forward \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(x)[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(m, (Segment, Pose, OBB)) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x)\n\u001b[1;32m    297\u001b[0m m\u001b[39m.\u001b[39mstride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([s \u001b[39m/\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m forward(torch\u001b[39m.\u001b[39mzeros(\u001b[39m1\u001b[39m, ch, s, s))])  \u001b[39m# forward\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mstride\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/nn/tasks.py:89\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):  \u001b[39m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/nn/tasks.py:107\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/nn/tasks.py:128\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 128\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[1;32m    129\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m, in \u001b[0;36mupsample_quant_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mupsampleop\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupsampleop(x)\n\u001b[0;32m---> 14\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49minterpolate(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3992\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3990\u001b[0m         scale_factors \u001b[39m=\u001b[39m [scale_factor \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(dim)]\n\u001b[1;32m   3991\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3992\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39meither size or scale_factor should be defined\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3994\u001b[0m \u001b[39mif\u001b[39;00m recompute_scale_factor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m recompute_scale_factor \u001b[39mand\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3995\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mrecompute_scale_factor is not meaningful with an explicit size.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: either size or scale_factor should be defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization.nn.modules import _utils as quant_nn_utils\n",
    "from ultralytics import YOLO\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def cal_model(model, data_loader, device, num_batch=1024):\n",
    "    num_batch = num_batch\n",
    "    def compute_amax(model, **kwargs):\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, quant_nn.TensorQuantizer):\n",
    "                if module._calibrator is not None:\n",
    "                    if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                        module.load_calib_amax(strict=False)\n",
    "                    else:\n",
    "                        module.load_calib_amax(**kwargs)\n",
    "\n",
    "                    module._amax = module._amax.to(device)\n",
    "        \n",
    "    def collect_stats(model, data_loader, device, num_batch=1024):\n",
    "        \"\"\"Feed data to the network and collect statistics\"\"\"\n",
    "        # Enable calibrators\n",
    "        model.eval()\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, quant_nn.TensorQuantizer):\n",
    "                if module._calibrator is not None:\n",
    "                    module.disable_quant()\n",
    "                    module.enable_calib()\n",
    "                else:\n",
    "                    module.disable()\n",
    "\n",
    "        # Feed data to the network for collecting stats\n",
    "        with torch.no_grad():\n",
    "            for i, datas in tqdm(enumerate(data_loader), total=num_batch, desc=\"Collect stats for calibrating\"):\n",
    "                # imgs = datas[0].to(device, non_blocking=True).float() / 255.0\n",
    "                imgs = datas['img'].to(device, non_blocking=True).float() / 255.0\n",
    "                model(imgs)\n",
    "\n",
    "                if i >= num_batch:\n",
    "                    break\n",
    "\n",
    "        # Disable calibrators\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, quant_nn.TensorQuantizer):\n",
    "                if module._calibrator is not None:\n",
    "                    module.enable_quant()\n",
    "                    module.disable_calib()\n",
    "                else:\n",
    "                    module.enable()\n",
    "\n",
    "    collect_stats(model, data_loader, device, num_batch=num_batch)\n",
    "    compute_amax(model, method=\"mse\")\n",
    "    \n",
    "def load_coco_dataset(data_dir, cache_file):\n",
    "    cache_path = os.path.join(data_dir, cache_file)\n",
    "\n",
    "    # ìºì‹œ íŒŒì¼ì´ ì¡´ìž¬í•˜ë©´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading dataset from cache: {cache_path}\")\n",
    "        dataset = torch.load(cache_path)\n",
    "    else:\n",
    "        # ìºì‹œ íŒŒì¼ì´ ì—†ìœ¼ë©´ ë°ì´í„°ì…‹ ìƒì„± ë° ìºì‹œ íŒŒì¼ ì €ìž¥\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((640, 640)),  # ì˜ˆì‹œ í¬ê¸°, ëª¨ë¸ ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ ì¡°ì •\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        dataset = datasets.CocoDetection(root=os.path.join(data_dir, 'images'), \n",
    "                                         annFile=os.path.join(data_dir, 'annotations/instances_train2017.json'), \n",
    "                                         transform=transform)\n",
    "        print(f\"Scanning dataset and creating cache: {cache_path}\")\n",
    "        torch.save(dataset, cache_path)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¡œë“œ ì˜ˆì‹œ\n",
    "data_dir = '/usr/src/datasets/coco'\n",
    "cache_file = 'labels/train2017.cache'\n",
    "dataset = load_coco_dataset(data_dir, cache_file)\n",
    "# DataLoader ìƒì„±\n",
    "batch_size = 2  # ë°°ì¹˜ í¬ê¸°, í•„ìš”ì— ë”°ë¼ ì¡°ì •\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "# COCO ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "\n",
    "model = YOLO('yolov8n_relu_int8.pt')\n",
    "# ëª¨ë¸ì„ GPUë¡œ ì˜®ê¸°ê¸° (GPU ì‚¬ìš©ì´ ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"cal_model\")\n",
    "# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•¨ìˆ˜ ì‹¤í–‰\n",
    "cal_model(model, train_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
