{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization.nn.modules import _utils as quant_nn_utils\n",
    "from ultralytics import YOLO\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "################################################################################\n",
    "import os\n",
    "import re\n",
    "from typing import List, Callable, Union, Dict\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # 이 줄을 추가하여 F.interpolate 사용 에러 해결\n",
    "import torch.optim as optim\n",
    "from torch.cuda import amp\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# Pytorch Quantization\n",
    "import pytorch_quantization\n",
    "\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "from pytorch_quantization.nn.modules import _utils as quant_nn_utils\n",
    "from pytorch_quantization import calib\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "from pytorch_quantization import quant_modules\n",
    "from pytorch_quantization import tensor_quant\n",
    "from absl import logging as quant_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_desc_input = QuantDescriptor(calib_method='histogram')\n",
    "quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)\n",
    "from pytorch_quantization import quant_modules\n",
    "quant_modules.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-3): 4 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-3): 4 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          384, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            576, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            960, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            576, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            960, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              64, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              64, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              64, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              192, 80, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              192, 80, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              192, 80, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): QuantConv2d(\n",
       "            16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(\"yolov8m.yaml\") \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantAdd(torch.nn.Module):\n",
    "    def __init__(self, quantization):\n",
    "        super().__init__()\n",
    "        if quantization:\n",
    "            self._input0_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "            self._input1_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "        self.quantization = quantization\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        if self.quantization:\n",
    "            print(f\"QAdd {self._input0_quantizer}  {self._input1_quantizer}\")\n",
    "            return self._input0_quantizer(x) + self._input1_quantizer(y)\n",
    "        return x + y\n",
    "\n",
    "class QuantC2fChunk(torch.nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self._input0_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "        self.c = c\n",
    "    def forward(self, x, chunks, dims):\n",
    "        return torch.split(self._input0_quantizer(x), (self.c, self.c), dims)\n",
    "\n",
    "class QuantConcat(torch.nn.Module): \n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self._input0_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "        self._input1_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x, dim):\n",
    "        x_0 = self._input0_quantizer(x[0])\n",
    "        x_1 = self._input1_quantizer(x[1])\n",
    "        return torch.cat((x_0, x_1), self.dim) \n",
    "\n",
    "class QuantUpsample(torch.nn.Module): \n",
    "    def __init__(self, size, scale_factor, mode):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self._input_quantizer = quant_nn.TensorQuantizer(QuantDescriptor())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.interpolate(self._input_quantizer(x), self.size, self.scale_factor, self.mode)\n",
    "    \n",
    "def bottleneck_quant_forward(self, x):\n",
    "    if hasattr(self, \"addop\"):\n",
    "        return self.addop(x, self.cv2(self.cv1(x))) if self.add else self.cv2(self.cv1(x))\n",
    "    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
    "\n",
    "def concat_quant_forward(self, x):\n",
    "    if hasattr(self, \"concatop\"):\n",
    "        return self.concatop(x, self.d)\n",
    "    return torch.cat(x, self.d)\n",
    "\n",
    "def upsample_quant_forward(self, x):\n",
    "    if hasattr(self, \"upsampleop\"):\n",
    "        return self.upsampleop(x)\n",
    "    return F.interpolate(x)\n",
    "\n",
    "def c2f_qaunt_forward(self, x):\n",
    "    if hasattr(self, \"c2fchunkop\"):\n",
    "        y = list(self.c2fchunkop(self.cv1(x), 2, 1))\n",
    "        y.extend(m(y[-1]) for m in self.m)\n",
    "        return self.cv2(torch.cat(y, 1))\n",
    "        \n",
    "    else:\n",
    "        y = list(self.cv1(x).split((self.c, self.c), 1))\n",
    "        y.extend(m(y[-1]) for m in self.m)\n",
    "        return self.cv2(torch.cat(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add C2fQuantChunk to model.model.2\n",
      "Add QuantAdd to model.model.2.m.0\n",
      "Add QuantAdd to model.model.2.m.1\n",
      "Add C2fQuantChunk to model.model.4\n",
      "Add QuantAdd to model.model.4.m.0\n",
      "Add QuantAdd to model.model.4.m.1\n",
      "Add QuantAdd to model.model.4.m.2\n",
      "Add QuantAdd to model.model.4.m.3\n",
      "Add C2fQuantChunk to model.model.6\n",
      "Add QuantAdd to model.model.6.m.0\n",
      "Add QuantAdd to model.model.6.m.1\n",
      "Add QuantAdd to model.model.6.m.2\n",
      "Add QuantAdd to model.model.6.m.3\n",
      "Add C2fQuantChunk to model.model.8\n",
      "Add QuantAdd to model.model.8.m.0\n",
      "Add QuantAdd to model.model.8.m.1\n",
      "Add QuantUpsample to model.model.10\n",
      "Add QuantConcat to model.model.11\n",
      "Add C2fQuantChunk to model.model.12\n",
      "Add QuantUpsample to model.model.13\n",
      "Add QuantConcat to model.model.14\n",
      "Add C2fQuantChunk to model.model.15\n",
      "Add QuantConcat to model.model.17\n",
      "Add C2fQuantChunk to model.model.18\n",
      "Add QuantConcat to model.model.20\n",
      "Add C2fQuantChunk to model.model.21\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if module.__class__.__name__ == \"C2f\":\n",
    "        if not hasattr(module, \"c2fchunkop\"):\n",
    "            print(f\"Add C2fQuantChunk to {name}\")\n",
    "            module.c2fchunkop = QuantC2fChunk(module.c)\n",
    "        module.__class__.forward = c2f_qaunt_forward\n",
    "\n",
    "    if module.__class__.__name__ == \"Bottleneck\":\n",
    "        if module.add:\n",
    "            if not hasattr(module, \"addop\"):\n",
    "                print(f\"Add QuantAdd to {name}\")\n",
    "                module.addop = QuantAdd(module.add)\n",
    "            module.__class__.forward = bottleneck_quant_forward\n",
    "            \n",
    "    if module.__class__.__name__ == \"Concat\":\n",
    "        if not hasattr(module, \"concatop\"):\n",
    "            print(f\"Add QuantConcat to {name}\")\n",
    "            module.concatop = QuantConcat(module.d)\n",
    "        module.__class__.forward = concat_quant_forward\n",
    "\n",
    "    if module.__class__.__name__ == \"Upsample\":\n",
    "        if not hasattr(module, \"upsampleop\"):\n",
    "            print(f\"Add QuantUpsample to {name}\")\n",
    "            module.upsampleop = QuantUpsample(module.size, module.scale_factor, module.mode)\n",
    "        module.__class__.forward = upsample_quant_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'yolov8_model_q.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (addop): QuantAdd(\n",
       "              (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-3): 4 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (addop): QuantAdd(\n",
       "              (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-3): 4 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (addop): QuantAdd(\n",
       "              (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          384, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (addop): QuantAdd(\n",
       "              (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            576, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(\n",
       "        scale_factor=2.0, mode='nearest'\n",
       "        (upsampleop): QuantUpsample(\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (11): Concat(\n",
       "        (concatop): QuantConcat(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            960, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(\n",
       "        scale_factor=2.0, mode='nearest'\n",
       "        (upsampleop): QuantUpsample(\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (14): Concat(\n",
       "        (concatop): QuantConcat(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat(\n",
       "        (concatop): QuantConcat(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            576, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): QuantConv2d(\n",
       "          384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat(\n",
       "        (concatop): QuantConcat(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          (_input1_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            960, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): QuantConv2d(\n",
       "            1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (c2fchunkop): QuantC2fChunk(\n",
       "          (_input0_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "        )\n",
       "      )\n",
       "      (22): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              64, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              64, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              64, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              192, 80, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              192, 80, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): QuantConv2d(\n",
       "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): QuantConv2d(\n",
       "              192, 80, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): QuantConv2d(\n",
       "            16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CocoDetection\n",
    "class CustomCocoDataset(CocoDetection):\n",
    "    def __init__(self, root, annFile, transform=None):\n",
    "        super(CustomCocoDataset, self).__init__(root, annFile)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super(CustomCocoDataset, self).__getitem__(index)\n",
    "        \n",
    "        # 이미지 전처리\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 타겟 데이터 변환 (예: boxes와 labels만 추출)\n",
    "        boxes = torch.tensor([t['bbox'] for t in target], dtype=torch.float32)\n",
    "        labels = torch.tensor([t['category_id'] for t in target], dtype=torch.int64)\n",
    "\n",
    "        # 타겟 사전 재구성\n",
    "        target = {'boxes': boxes, 'labels': labels}\n",
    "\n",
    "        return img, target\n",
    "\n",
    "# 데이터셋과 데이터 로더 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    filtered_batch = [item for item in batch if item[1]['boxes'].shape[0] > 0]\n",
    "    \n",
    "    # 필터링된 배치에서 이미지와 타겟 분리\n",
    "    images = [item[0] for item in filtered_batch]\n",
    "    targets = [item[1] for item in filtered_batch]\n",
    "\n",
    "    # 이미지 텐서 스택\n",
    "    images = torch.stack(images, dim=0)\n",
    "\n",
    "    # targets에서 'boxes'와 'labels' 추출 및 텐서 변환\n",
    "    # boxes = [torch.tensor(t['boxes'], dtype=torch.float32) for t in targets]\n",
    "    # labels = [torch.tensor(t['labels'], dtype=torch.int64) for t in targets]\n",
    "    boxes = [t['boxes'].clone().detach().float() for t in targets]\n",
    "    labels = [t['labels'].clone().detach().long() for t in targets]\n",
    "    # pad_sequence로 모든 boxes와 labels를 동일한 길이로 패딩\n",
    "    boxes_padded = pad_sequence(boxes, batch_first=True, padding_value=0)\n",
    "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=-1)  # 레이블 패딩 값으로 -1을 사용할 수 있습니다.\n",
    "\n",
    "    # 패딩된 boxes와 labels를 사용하여 targets 구조 재구성\n",
    "    targets_padded = [{'boxes': b, 'labels': l} for b, l in zip(boxes_padded, labels_padded)]\n",
    "\n",
    "    return images, targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7f33436171c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1145, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1274, in close\n",
      "    if self.last_print_t < self.start_t + self.delay:\n",
      "AttributeError: 'tqdm' object has no attribute 'last_print_t'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7f33436171c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1145, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1274, in close\n",
      "    if self.last_print_t < self.start_t + self.delay:\n",
      "AttributeError: 'tqdm' object has no attribute 'last_print_t'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7f33436171c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1145, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1274, in close\n",
      "    if self.last_print_t < self.start_t + self.delay:\n",
      "AttributeError: 'tqdm' object has no attribute 'last_print_t'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=14.67s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.33s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "data_path = \"/usr/src/datasets/coco/labels\"\n",
    "batch_size = 16\n",
    "train_data_dir = '/DL_data_super_hdd/coco_dataset/data/images/train2017'\n",
    "val_data_dir = '/DL_data_super_hdd/coco_dataset/data/images/val2017/'\n",
    "train_ann_file = '/DL_data_super_hdd/coco_dataset/annotations/instances_train2017.json'\n",
    "val_ann_file = '/DL_data_super_hdd/coco_dataset/annotations/instances_val2017.json'\n",
    "dataset = CustomCocoDataset(root=train_data_dir, annFile=train_ann_file, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True,collate_fn=collate_fn)\n",
    "dataset_test = CustomCocoDataset(root=val_data_dir, annFile=val_ann_file, transform=transform)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=16, shuffle=True,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_model(model, data_loader, device, num_batch=2):\n",
    "    num_batch = num_batch\n",
    "    def compute_amax(model, **kwargs):\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, quant_nn.TensorQuantizer):\n",
    "                if module._calibrator is not None:\n",
    "                    if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                        module.load_calib_amax(strict=False)\n",
    "                    else:\n",
    "                        module.load_calib_amax(**kwargs)\n",
    "\n",
    "                    module._amax = module._amax.to(device)\n",
    "        \n",
    "    def collect_stats(model, data_loader, device, num_batch=2):\n",
    "        \"\"\"Feed data to the network and collect statistics\"\"\"\n",
    "        # Enable calibrators\n",
    "        # model.eval()\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, quant_nn.TensorQuantizer):\n",
    "                if module._calibrator is not None:\n",
    "                    module.disable_quant()\n",
    "                    module.enable_calib()\n",
    "                else:\n",
    "                    module.disable()\n",
    "\n",
    "        # Feed data to the network for collecting stats\n",
    "        with torch.no_grad():\n",
    "            for i, datas in tqdm(enumerate(data_loader), total=num_batch, desc=\"Collect stats for calibrating\"):\n",
    "                imgs = datas[0].to(device, non_blocking=True).float() / 255.0\n",
    "                # imgs = datas['img'].to(device, non_blocking=True).float() / 255.0\n",
    "                model(imgs)\n",
    "\n",
    "                if i >= num_batch:\n",
    "                    break\n",
    "\n",
    "        # Disable calibrators\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, quant_nn.TensorQuantizer):\n",
    "                if module._calibrator is not None:\n",
    "                    module.enable_quant()\n",
    "                    module.disable_calib()\n",
    "                else:\n",
    "                    module.enable()\n",
    "    with torch.no_grad():\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        collect_stats(model, data_loader, device)\n",
    "        compute_amax(model, method=\"percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collect stats for calibrating:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43918/14100771.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes = [torch.tensor(t['boxes'], dtype=torch.float32) for t in targets]\n",
      "/tmp/ipykernel_43918/14100771.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(t['labels'], dtype=torch.int64) for t in targets]\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_quantization-2.2.0-py3.10-linux-x86_64.egg/pytorch_quantization/calib/histogram.py:115: UserWarning: _histc_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
      "  hist = torch.histc(x, bins=self._num_bins, min=0, max=self._calib_bin_edges[-1])\n",
      "Collect stats for calibrating:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n",
      "QAdd TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)  TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=MaxCalibrator scale=1.0 calib)\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     cal_model(model, data_loader_test, device)\n\u001b[1;32m      4\u001b[0m         \u001b[39m# collect_stats(model, data_loader, device)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         \u001b[39m# compute_amax(model, method=\"percentile\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 46\u001b[0m, in \u001b[0;36mcal_model\u001b[0;34m(model, data_loader, device, num_batch)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     45\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m     collect_stats(model, data_loader, device)\n\u001b[1;32m     47\u001b[0m     compute_amax(model, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpercentile\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[50], line 31\u001b[0m, in \u001b[0;36mcal_model.<locals>.collect_stats\u001b[0;34m(model, data_loader, device, num_batch)\u001b[0m\n\u001b[1;32m     29\u001b[0m imgs \u001b[39m=\u001b[39m datas[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mfloat() \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[39m# imgs = datas['img'].to(device, non_blocking=True).float() / 255.0\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m model(imgs)\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m num_batch:\n\u001b[1;32m     34\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/engine/model.py:177\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    155\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    156\u001b[0m     source: Union[\u001b[39mstr\u001b[39m, Path, \u001b[39mint\u001b[39m, \u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, np\u001b[39m.\u001b[39mndarray, torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    157\u001b[0m     stream: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    159\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m    160\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m    An alias for the predict method, enabling the model instance to be callable.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39m        (List[ultralytics.engine.results.Results]): A list of prediction results, encapsulated in the Results class.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(source, stream, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/engine/model.py:453\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39mif\u001b[39;00m prompts \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor, \u001b[39m\"\u001b[39m\u001b[39mset_prompts\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/engine/predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream_inference(source, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[39m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     37\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[39m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/engine/predictor.py:248\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39m# Inference\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39mwith\u001b[39;00m profilers[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 248\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference(im, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39membed:\n\u001b[1;32m    250\u001b[0m         \u001b[39myield from\u001b[39;00m [preds] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(preds, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m preds  \u001b[39m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/engine/predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m visualize \u001b[39m=\u001b[39m (\n\u001b[1;32m    138\u001b[0m     increment_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir \u001b[39m/\u001b[39m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mstem, mkdir\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mvisualize \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_type\u001b[39m.\u001b[39mtensor)\n\u001b[1;32m    140\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im, augment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49maugment, visualize\u001b[39m=\u001b[39;49mvisualize, embed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49membed, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/nn/autobackend.py:453\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39m# PyTorch\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpt \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_module:\n\u001b[0;32m--> 453\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im, augment\u001b[39m=\u001b[39;49maugment, visualize\u001b[39m=\u001b[39;49mvisualize, embed\u001b[39m=\u001b[39;49membed)\n\u001b[1;32m    455\u001b[0m \u001b[39m# TorchScript\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/nn/tasks.py:89\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):  \u001b[39m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/nn/tasks.py:107\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/nn/tasks.py:128\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 128\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[1;32m    129\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/works/ultralytics/ultralytics/nn/modules/head.py:47\u001b[0m, in \u001b[0;36mDetect.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Concatenates and returns predicted bounding boxes and class probabilities.\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnl):\n\u001b[0;32m---> 47\u001b[0m     x[i] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv2[i](x[i]), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv3[i](x[i])), \u001b[39m1\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:  \u001b[39m# Training path\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_quantization-2.2.0-py3.10-linux-x86_64.egg/pytorch_quantization/nn/modules/quant_conv.py:121\u001b[0m, in \u001b[0;36mQuantConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    120\u001b[0m     \u001b[39m# the actual quantization happens in the next level of the class hierarchy\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     quant_input, quant_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_quant(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcircular\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    124\u001b[0m         expanded_padding \u001b[39m=\u001b[39m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding[\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[1;32m    125\u001b[0m                             (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_quantization-2.2.0-py3.10-linux-x86_64.egg/pytorch_quantization/nn/modules/quant_conv.py:86\u001b[0m, in \u001b[0;36m_QuantConvNd._quant\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_quant\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m     76\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply quantization on input and weight\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[39m    Function called by the classes lower in the hierarchy, which actually performs the quantization before forward\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m        A tuple: (quant_in_feature, quant_weight)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     quant_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_quantizer(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     87\u001b[0m     quant_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weight_quantizer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight)\n\u001b[1;32m     89\u001b[0m     \u001b[39mreturn\u001b[39;00m (quant_input, quant_weight)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_quantization-2.2.0-py3.10-linux-x86_64.egg/pytorch_quantization/nn/modules/tensor_quantizer.py:367\u001b[0m, in \u001b[0;36mTensorQuantizer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCalibrator was not created.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    366\u001b[0m     \u001b[39m# Shape is only known when it sees the first tensor\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calibrator\u001b[39m.\u001b[39;49mcollect(inputs)\n\u001b[1;32m    369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_if_clip:\n\u001b[1;32m    370\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_learn_amax:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_quantization-2.2.0-py3.10-linux-x86_64.egg/pytorch_quantization/calib/histogram.py:112\u001b[0m, in \u001b[0;36mHistogramCalibrator.collect\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mif\u001b[39;00m x_max \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calib_bin_edges[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m    111\u001b[0m     width \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calib_bin_edges[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calib_bin_edges[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_bins \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m((x_max \u001b[39m/\u001b[39;49m width)\u001b[39m.\u001b[39;49mceil()\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m    113\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calib_bin_edges \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, x_max \u001b[39m+\u001b[39m width, width, device\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    115\u001b[0m hist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhistc(x, bins\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_bins, \u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calib_bin_edges[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cal_model(model, data_loader, device)\n",
    "        # collect_stats(model, data_loader, device)\n",
    "        # compute_amax(model, method=\"percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# with torch.no_grad():\n",
    "#     evaluate(model, criterion, data_loader_test, device=\"cuda\", print_freq=20)\n",
    "    \n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"quant_05271800-calibrated.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for YOLO:\n\tMissing key(s) in state_dict: \"model.model.0.bn.weight\", \"model.model.0.bn.bias\", \"model.model.0.bn.running_mean\", \"model.model.0.bn.running_var\", \"model.model.1.bn.weight\", \"model.model.1.bn.bias\", \"model.model.1.bn.running_mean\", \"model.model.1.bn.running_var\", \"model.model.2.cv1.bn.weight\", \"model.model.2.cv1.bn.bias\", \"model.model.2.cv1.bn.running_mean\", \"model.model.2.cv1.bn.running_var\", \"model.model.2.cv2.bn.weight\", \"model.model.2.cv2.bn.bias\", \"model.model.2.cv2.bn.running_mean\", \"model.model.2.cv2.bn.running_var\", \"model.model.2.m.0.cv1.bn.weight\", \"model.model.2.m.0.cv1.bn.bias\", \"model.model.2.m.0.cv1.bn.running_mean\", \"model.model.2.m.0.cv1.bn.running_var\", \"model.model.2.m.0.cv2.bn.weight\", \"model.model.2.m.0.cv2.bn.bias\", \"model.model.2.m.0.cv2.bn.running_mean\", \"model.model.2.m.0.cv2.bn.running_var\", \"model.model.3.bn.weight\", \"model.model.3.bn.bias\", \"model.model.3.bn.running_mean\", \"model.model.3.bn.running_var\", \"model.model.4.cv1.bn.weight\", \"model.model.4.cv1.bn.bias\", \"model.model.4.cv1.bn.running_mean\", \"model.model.4.cv1.bn.running_var\", \"model.model.4.cv2.bn.weight\", \"model.model.4.cv2.bn.bias\", \"model.model.4.cv2.bn.running_mean\", \"model.model.4.cv2.bn.running_var\", \"model.model.4.m.0.cv1.bn.weight\", \"model.model.4.m.0.cv1.bn.bias\", \"model.model.4.m.0.cv1.bn.running_mean\", \"model.model.4.m.0.cv1.bn.running_var\", \"model.model.4.m.0.cv2.bn.weight\", \"model.model.4.m.0.cv2.bn.bias\", \"model.model.4.m.0.cv2.bn.running_mean\", \"model.model.4.m.0.cv2.bn.running_var\", \"model.model.4.m.1.cv1.bn.weight\", \"model.model.4.m.1.cv1.bn.bias\", \"model.model.4.m.1.cv1.bn.running_mean\", \"model.model.4.m.1.cv1.bn.running_var\", \"model.model.4.m.1.cv2.bn.weight\", \"model.model.4.m.1.cv2.bn.bias\", \"model.model.4.m.1.cv2.bn.running_mean\", \"model.model.4.m.1.cv2.bn.running_var\", \"model.model.5.bn.weight\", \"model.model.5.bn.bias\", \"model.model.5.bn.running_mean\", \"model.model.5.bn.running_var\", \"model.model.6.cv1.bn.weight\", \"model.model.6.cv1.bn.bias\", \"model.model.6.cv1.bn.running_mean\", \"model.model.6.cv1.bn.running_var\", \"model.model.6.cv2.bn.weight\", \"model.model.6.cv2.bn.bias\", \"model.model.6.cv2.bn.running_mean\", \"model.model.6.cv2.bn.running_var\", \"model.model.6.m.0.cv1.bn.weight\", \"model.model.6.m.0.cv1.bn.bias\", \"model.model.6.m.0.cv1.bn.running_mean\", \"model.model.6.m.0.cv1.bn.running_var\", \"model.model.6.m.0.cv2.bn.weight\", \"model.model.6.m.0.cv2.bn.bias\", \"model.model.6.m.0.cv2.bn.running_mean\", \"model.model.6.m.0.cv2.bn.running_var\", \"model.model.6.m.1.cv1.bn.weight\", \"model.model.6.m.1.cv1.bn.bias\", \"model.model.6.m.1.cv1.bn.running_mean\", \"model.model.6.m.1.cv1.bn.running_var\", \"model.model.6.m.1.cv2.bn.weight\", \"model.model.6.m.1.cv2.bn.bias\", \"model.model.6.m.1.cv2.bn.running_mean\", \"model.model.6.m.1.cv2.bn.running_var\", \"model.model.7.bn.weight\", \"model.model.7.bn.bias\", \"model.model.7.bn.running_mean\", \"model.model.7.bn.running_var\", \"model.model.8.cv1.bn.weight\", \"model.model.8.cv1.bn.bias\", \"model.model.8.cv1.bn.running_mean\", \"model.model.8.cv1.bn.running_var\", \"model.model.8.cv2.bn.weight\", \"model.model.8.cv2.bn.bias\", \"model.model.8.cv2.bn.running_mean\", \"model.model.8.cv2.bn.running_var\", \"model.model.8.m.0.cv1.bn.weight\", \"model.model.8.m.0.cv1.bn.bias\", \"model.model.8.m.0.cv1.bn.running_mean\", \"model.model.8.m.0.cv1.bn.running_var\", \"model.model.8.m.0.cv2.bn.weight\", \"model.model.8.m.0.cv2.bn.bias\", \"model.model.8.m.0.cv2.bn.running_mean\", \"model.model.8.m.0.cv2.bn.running_var\", \"model.model.9.cv1.bn.weight\", \"model.model.9.cv1.bn.bias\", \"model.model.9.cv1.bn.running_mean\", \"model.model.9.cv1.bn.running_var\", \"model.model.9.cv2.bn.weight\", \"model.model.9.cv2.bn.bias\", \"model.model.9.cv2.bn.running_mean\", \"model.model.9.cv2.bn.running_var\", \"model.model.12.cv1.bn.weight\", \"model.model.12.cv1.bn.bias\", \"model.model.12.cv1.bn.running_mean\", \"model.model.12.cv1.bn.running_var\", \"model.model.12.cv2.bn.weight\", \"model.model.12.cv2.bn.bias\", \"model.model.12.cv2.bn.running_mean\", \"model.model.12.cv2.bn.running_var\", \"model.model.12.m.0.cv1.bn.weight\", \"model.model.12.m.0.cv1.bn.bias\", \"model.model.12.m.0.cv1.bn.running_mean\", \"model.model.12.m.0.cv1.bn.running_var\", \"model.model.12.m.0.cv2.bn.weight\", \"model.model.12.m.0.cv2.bn.bias\", \"model.model.12.m.0.cv2.bn.running_mean\", \"model.model.12.m.0.cv2.bn.running_var\", \"model.model.15.cv1.bn.weight\", \"model.model.15.cv1.bn.bias\", \"model.model.15.cv1.bn.running_mean\", \"model.model.15.cv1.bn.running_var\", \"model.model.15.cv2.bn.weight\", \"model.model.15.cv2.bn.bias\", \"model.model.15.cv2.bn.running_mean\", \"model.model.15.cv2.bn.running_var\", \"model.model.15.m.0.cv1.bn.weight\", \"model.model.15.m.0.cv1.bn.bias\", \"model.model.15.m.0.cv1.bn.running_mean\", \"model.model.15.m.0.cv1.bn.running_var\", \"model.model.15.m.0.cv2.bn.weight\", \"model.model.15.m.0.cv2.bn.bias\", \"model.model.15.m.0.cv2.bn.running_mean\", \"model.model.15.m.0.cv2.bn.running_var\", \"model.model.16.bn.weight\", \"model.model.16.bn.bias\", \"model.model.16.bn.running_mean\", \"model.model.16.bn.running_var\", \"model.model.18.cv1.bn.weight\", \"model.model.18.cv1.bn.bias\", \"model.model.18.cv1.bn.running_mean\", \"model.model.18.cv1.bn.running_var\", \"model.model.18.cv2.bn.weight\", \"model.model.18.cv2.bn.bias\", \"model.model.18.cv2.bn.running_mean\", \"model.model.18.cv2.bn.running_var\", \"model.model.18.m.0.cv1.bn.weight\", \"model.model.18.m.0.cv1.bn.bias\", \"model.model.18.m.0.cv1.bn.running_mean\", \"model.model.18.m.0.cv1.bn.running_var\", \"model.model.18.m.0.cv2.bn.weight\", \"model.model.18.m.0.cv2.bn.bias\", \"model.model.18.m.0.cv2.bn.running_mean\", \"model.model.18.m.0.cv2.bn.running_var\", \"model.model.19.bn.weight\", \"model.model.19.bn.bias\", \"model.model.19.bn.running_mean\", \"model.model.19.bn.running_var\", \"model.model.21.cv1.bn.weight\", \"model.model.21.cv1.bn.bias\", \"model.model.21.cv1.bn.running_mean\", \"model.model.21.cv1.bn.running_var\", \"model.model.21.cv2.bn.weight\", \"model.model.21.cv2.bn.bias\", \"model.model.21.cv2.bn.running_mean\", \"model.model.21.cv2.bn.running_var\", \"model.model.21.m.0.cv1.bn.weight\", \"model.model.21.m.0.cv1.bn.bias\", \"model.model.21.m.0.cv1.bn.running_mean\", \"model.model.21.m.0.cv1.bn.running_var\", \"model.model.21.m.0.cv2.bn.weight\", \"model.model.21.m.0.cv2.bn.bias\", \"model.model.21.m.0.cv2.bn.running_mean\", \"model.model.21.m.0.cv2.bn.running_var\", \"model.model.22.cv2.0.0.bn.weight\", \"model.model.22.cv2.0.0.bn.bias\", \"model.model.22.cv2.0.0.bn.running_mean\", \"model.model.22.cv2.0.0.bn.running_var\", \"model.model.22.cv2.0.1.bn.weight\", \"model.model.22.cv2.0.1.bn.bias\", \"model.model.22.cv2.0.1.bn.running_mean\", \"model.model.22.cv2.0.1.bn.running_var\", \"model.model.22.cv2.1.0.bn.weight\", \"model.model.22.cv2.1.0.bn.bias\", \"model.model.22.cv2.1.0.bn.running_mean\", \"model.model.22.cv2.1.0.bn.running_var\", \"model.model.22.cv2.1.1.bn.weight\", \"model.model.22.cv2.1.1.bn.bias\", \"model.model.22.cv2.1.1.bn.running_mean\", \"model.model.22.cv2.1.1.bn.running_var\", \"model.model.22.cv2.2.0.bn.weight\", \"model.model.22.cv2.2.0.bn.bias\", \"model.model.22.cv2.2.0.bn.running_mean\", \"model.model.22.cv2.2.0.bn.running_var\", \"model.model.22.cv2.2.1.bn.weight\", \"model.model.22.cv2.2.1.bn.bias\", \"model.model.22.cv2.2.1.bn.running_mean\", \"model.model.22.cv2.2.1.bn.running_var\", \"model.model.22.cv3.0.0.bn.weight\", \"model.model.22.cv3.0.0.bn.bias\", \"model.model.22.cv3.0.0.bn.running_mean\", \"model.model.22.cv3.0.0.bn.running_var\", \"model.model.22.cv3.0.1.bn.weight\", \"model.model.22.cv3.0.1.bn.bias\", \"model.model.22.cv3.0.1.bn.running_mean\", \"model.model.22.cv3.0.1.bn.running_var\", \"model.model.22.cv3.1.0.bn.weight\", \"model.model.22.cv3.1.0.bn.bias\", \"model.model.22.cv3.1.0.bn.running_mean\", \"model.model.22.cv3.1.0.bn.running_var\", \"model.model.22.cv3.1.1.bn.weight\", \"model.model.22.cv3.1.1.bn.bias\", \"model.model.22.cv3.1.1.bn.running_mean\", \"model.model.22.cv3.1.1.bn.running_var\", \"model.model.22.cv3.2.0.bn.weight\", \"model.model.22.cv3.2.0.bn.bias\", \"model.model.22.cv3.2.0.bn.running_mean\", \"model.model.22.cv3.2.0.bn.running_var\", \"model.model.22.cv3.2.1.bn.weight\", \"model.model.22.cv3.2.1.bn.bias\", \"model.model.22.cv3.2.1.bn.running_mean\", \"model.model.22.cv3.2.1.bn.running_var\". \n\tUnexpected key(s) in state_dict: \"model.model.0.conv.bias\", \"model.model.0.conv._input_quantizer._amax\", \"model.model.0.conv._weight_quantizer._amax\", \"model.model.1.conv.bias\", \"model.model.1.conv._input_quantizer._amax\", \"model.model.1.conv._weight_quantizer._amax\", \"model.model.2.c2fchunkop._input0_quantizer._amax\", \"model.model.2.cv1.conv.bias\", \"model.model.2.cv1.conv._input_quantizer._amax\", \"model.model.2.cv1.conv._weight_quantizer._amax\", \"model.model.2.cv2.conv.bias\", \"model.model.2.cv2.conv._input_quantizer._amax\", \"model.model.2.cv2.conv._weight_quantizer._amax\", \"model.model.2.m.1.cv1.conv.weight\", \"model.model.2.m.1.cv1.conv.bias\", \"model.model.2.m.1.cv1.conv._input_quantizer._amax\", \"model.model.2.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.2.m.1.cv2.conv.weight\", \"model.model.2.m.1.cv2.conv.bias\", \"model.model.2.m.1.cv2.conv._input_quantizer._amax\", \"model.model.2.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.2.m.1.addop._input0_quantizer._amax\", \"model.model.2.m.1.addop._input1_quantizer._amax\", \"model.model.2.m.0.addop._input0_quantizer._amax\", \"model.model.2.m.0.addop._input1_quantizer._amax\", \"model.model.2.m.0.cv1.conv.bias\", \"model.model.2.m.0.cv1.conv._input_quantizer._amax\", \"model.model.2.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.2.m.0.cv2.conv.bias\", \"model.model.2.m.0.cv2.conv._input_quantizer._amax\", \"model.model.2.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.3.conv.bias\", \"model.model.3.conv._input_quantizer._amax\", \"model.model.3.conv._weight_quantizer._amax\", \"model.model.4.c2fchunkop._input0_quantizer._amax\", \"model.model.4.cv1.conv.bias\", \"model.model.4.cv1.conv._input_quantizer._amax\", \"model.model.4.cv1.conv._weight_quantizer._amax\", \"model.model.4.cv2.conv.bias\", \"model.model.4.cv2.conv._input_quantizer._amax\", \"model.model.4.cv2.conv._weight_quantizer._amax\", \"model.model.4.m.2.cv1.conv.weight\", \"model.model.4.m.2.cv1.conv.bias\", \"model.model.4.m.2.cv1.conv._input_quantizer._amax\", \"model.model.4.m.2.cv1.conv._weight_quantizer._amax\", \"model.model.4.m.2.cv2.conv.weight\", \"model.model.4.m.2.cv2.conv.bias\", \"model.model.4.m.2.cv2.conv._input_quantizer._amax\", \"model.model.4.m.2.cv2.conv._weight_quantizer._amax\", \"model.model.4.m.2.addop._input0_quantizer._amax\", \"model.model.4.m.2.addop._input1_quantizer._amax\", \"model.model.4.m.3.cv1.conv.weight\", \"model.model.4.m.3.cv1.conv.bias\", \"model.model.4.m.3.cv1.conv._input_quantizer._amax\", \"model.model.4.m.3.cv1.conv._weight_quantizer._amax\", \"model.model.4.m.3.cv2.conv.weight\", \"model.model.4.m.3.cv2.conv.bias\", \"model.model.4.m.3.cv2.conv._input_quantizer._amax\", \"model.model.4.m.3.cv2.conv._weight_quantizer._amax\", \"model.model.4.m.3.addop._input0_quantizer._amax\", \"model.model.4.m.3.addop._input1_quantizer._amax\", \"model.model.4.m.0.addop._input0_quantizer._amax\", \"model.model.4.m.0.addop._input1_quantizer._amax\", \"model.model.4.m.0.cv1.conv.bias\", \"model.model.4.m.0.cv1.conv._input_quantizer._amax\", \"model.model.4.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.4.m.0.cv2.conv.bias\", \"model.model.4.m.0.cv2.conv._input_quantizer._amax\", \"model.model.4.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.4.m.1.addop._input0_quantizer._amax\", \"model.model.4.m.1.addop._input1_quantizer._amax\", \"model.model.4.m.1.cv1.conv.bias\", \"model.model.4.m.1.cv1.conv._input_quantizer._amax\", \"model.model.4.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.4.m.1.cv2.conv.bias\", \"model.model.4.m.1.cv2.conv._input_quantizer._amax\", \"model.model.4.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.5.conv.bias\", \"model.model.5.conv._input_quantizer._amax\", \"model.model.5.conv._weight_quantizer._amax\", \"model.model.6.c2fchunkop._input0_quantizer._amax\", \"model.model.6.cv1.conv.bias\", \"model.model.6.cv1.conv._input_quantizer._amax\", \"model.model.6.cv1.conv._weight_quantizer._amax\", \"model.model.6.cv2.conv.bias\", \"model.model.6.cv2.conv._input_quantizer._amax\", \"model.model.6.cv2.conv._weight_quantizer._amax\", \"model.model.6.m.2.cv1.conv.weight\", \"model.model.6.m.2.cv1.conv.bias\", \"model.model.6.m.2.cv1.conv._input_quantizer._amax\", \"model.model.6.m.2.cv1.conv._weight_quantizer._amax\", \"model.model.6.m.2.cv2.conv.weight\", \"model.model.6.m.2.cv2.conv.bias\", \"model.model.6.m.2.cv2.conv._input_quantizer._amax\", \"model.model.6.m.2.cv2.conv._weight_quantizer._amax\", \"model.model.6.m.2.addop._input0_quantizer._amax\", \"model.model.6.m.2.addop._input1_quantizer._amax\", \"model.model.6.m.3.cv1.conv.weight\", \"model.model.6.m.3.cv1.conv.bias\", \"model.model.6.m.3.cv1.conv._input_quantizer._amax\", \"model.model.6.m.3.cv1.conv._weight_quantizer._amax\", \"model.model.6.m.3.cv2.conv.weight\", \"model.model.6.m.3.cv2.conv.bias\", \"model.model.6.m.3.cv2.conv._input_quantizer._amax\", \"model.model.6.m.3.cv2.conv._weight_quantizer._amax\", \"model.model.6.m.3.addop._input0_quantizer._amax\", \"model.model.6.m.3.addop._input1_quantizer._amax\", \"model.model.6.m.0.addop._input0_quantizer._amax\", \"model.model.6.m.0.addop._input1_quantizer._amax\", \"model.model.6.m.0.cv1.conv.bias\", \"model.model.6.m.0.cv1.conv._input_quantizer._amax\", \"model.model.6.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.6.m.0.cv2.conv.bias\", \"model.model.6.m.0.cv2.conv._input_quantizer._amax\", \"model.model.6.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.6.m.1.addop._input0_quantizer._amax\", \"model.model.6.m.1.addop._input1_quantizer._amax\", \"model.model.6.m.1.cv1.conv.bias\", \"model.model.6.m.1.cv1.conv._input_quantizer._amax\", \"model.model.6.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.6.m.1.cv2.conv.bias\", \"model.model.6.m.1.cv2.conv._input_quantizer._amax\", \"model.model.6.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.7.conv.bias\", \"model.model.7.conv._input_quantizer._amax\", \"model.model.7.conv._weight_quantizer._amax\", \"model.model.8.c2fchunkop._input0_quantizer._amax\", \"model.model.8.cv1.conv.bias\", \"model.model.8.cv1.conv._input_quantizer._amax\", \"model.model.8.cv1.conv._weight_quantizer._amax\", \"model.model.8.cv2.conv.bias\", \"model.model.8.cv2.conv._input_quantizer._amax\", \"model.model.8.cv2.conv._weight_quantizer._amax\", \"model.model.8.m.1.cv1.conv.weight\", \"model.model.8.m.1.cv1.conv.bias\", \"model.model.8.m.1.cv1.conv._input_quantizer._amax\", \"model.model.8.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.8.m.1.cv2.conv.weight\", \"model.model.8.m.1.cv2.conv.bias\", \"model.model.8.m.1.cv2.conv._input_quantizer._amax\", \"model.model.8.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.8.m.1.addop._input0_quantizer._amax\", \"model.model.8.m.1.addop._input1_quantizer._amax\", \"model.model.8.m.0.addop._input0_quantizer._amax\", \"model.model.8.m.0.addop._input1_quantizer._amax\", \"model.model.8.m.0.cv1.conv.bias\", \"model.model.8.m.0.cv1.conv._input_quantizer._amax\", \"model.model.8.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.8.m.0.cv2.conv.bias\", \"model.model.8.m.0.cv2.conv._input_quantizer._amax\", \"model.model.8.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.9.cv1.conv.bias\", \"model.model.9.cv1.conv._input_quantizer._amax\", \"model.model.9.cv1.conv._weight_quantizer._amax\", \"model.model.9.cv2.conv.bias\", \"model.model.9.cv2.conv._input_quantizer._amax\", \"model.model.9.cv2.conv._weight_quantizer._amax\", \"model.model.10.upsampleop._input_quantizer._amax\", \"model.model.11.concatop._input0_quantizer._amax\", \"model.model.11.concatop._input1_quantizer._amax\", \"model.model.12.c2fchunkop._input0_quantizer._amax\", \"model.model.12.cv1.conv.bias\", \"model.model.12.cv1.conv._input_quantizer._amax\", \"model.model.12.cv1.conv._weight_quantizer._amax\", \"model.model.12.cv2.conv.bias\", \"model.model.12.cv2.conv._input_quantizer._amax\", \"model.model.12.cv2.conv._weight_quantizer._amax\", \"model.model.12.m.1.cv1.conv.weight\", \"model.model.12.m.1.cv1.conv.bias\", \"model.model.12.m.1.cv1.conv._input_quantizer._amax\", \"model.model.12.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.12.m.1.cv2.conv.weight\", \"model.model.12.m.1.cv2.conv.bias\", \"model.model.12.m.1.cv2.conv._input_quantizer._amax\", \"model.model.12.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.12.m.0.cv1.conv.bias\", \"model.model.12.m.0.cv1.conv._input_quantizer._amax\", \"model.model.12.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.12.m.0.cv2.conv.bias\", \"model.model.12.m.0.cv2.conv._input_quantizer._amax\", \"model.model.12.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.13.upsampleop._input_quantizer._amax\", \"model.model.14.concatop._input0_quantizer._amax\", \"model.model.14.concatop._input1_quantizer._amax\", \"model.model.15.c2fchunkop._input0_quantizer._amax\", \"model.model.15.cv1.conv.bias\", \"model.model.15.cv1.conv._input_quantizer._amax\", \"model.model.15.cv1.conv._weight_quantizer._amax\", \"model.model.15.cv2.conv.bias\", \"model.model.15.cv2.conv._input_quantizer._amax\", \"model.model.15.cv2.conv._weight_quantizer._amax\", \"model.model.15.m.1.cv1.conv.weight\", \"model.model.15.m.1.cv1.conv.bias\", \"model.model.15.m.1.cv1.conv._input_quantizer._amax\", \"model.model.15.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.15.m.1.cv2.conv.weight\", \"model.model.15.m.1.cv2.conv.bias\", \"model.model.15.m.1.cv2.conv._input_quantizer._amax\", \"model.model.15.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.15.m.0.cv1.conv.bias\", \"model.model.15.m.0.cv1.conv._input_quantizer._amax\", \"model.model.15.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.15.m.0.cv2.conv.bias\", \"model.model.15.m.0.cv2.conv._input_quantizer._amax\", \"model.model.15.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.16.conv.bias\", \"model.model.16.conv._input_quantizer._amax\", \"model.model.16.conv._weight_quantizer._amax\", \"model.model.17.concatop._input0_quantizer._amax\", \"model.model.17.concatop._input1_quantizer._amax\", \"model.model.18.c2fchunkop._input0_quantizer._amax\", \"model.model.18.cv1.conv.bias\", \"model.model.18.cv1.conv._input_quantizer._amax\", \"model.model.18.cv1.conv._weight_quantizer._amax\", \"model.model.18.cv2.conv.bias\", \"model.model.18.cv2.conv._input_quantizer._amax\", \"model.model.18.cv2.conv._weight_quantizer._amax\", \"model.model.18.m.1.cv1.conv.weight\", \"model.model.18.m.1.cv1.conv.bias\", \"model.model.18.m.1.cv1.conv._input_quantizer._amax\", \"model.model.18.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.18.m.1.cv2.conv.weight\", \"model.model.18.m.1.cv2.conv.bias\", \"model.model.18.m.1.cv2.conv._input_quantizer._amax\", \"model.model.18.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.18.m.0.cv1.conv.bias\", \"model.model.18.m.0.cv1.conv._input_quantizer._amax\", \"model.model.18.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.18.m.0.cv2.conv.bias\", \"model.model.18.m.0.cv2.conv._input_quantizer._amax\", \"model.model.18.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.19.conv.bias\", \"model.model.19.conv._input_quantizer._amax\", \"model.model.19.conv._weight_quantizer._amax\", \"model.model.20.concatop._input0_quantizer._amax\", \"model.model.20.concatop._input1_quantizer._amax\", \"model.model.21.c2fchunkop._input0_quantizer._amax\", \"model.model.21.cv1.conv.bias\", \"model.model.21.cv1.conv._input_quantizer._amax\", \"model.model.21.cv1.conv._weight_quantizer._amax\", \"model.model.21.cv2.conv.bias\", \"model.model.21.cv2.conv._input_quantizer._amax\", \"model.model.21.cv2.conv._weight_quantizer._amax\", \"model.model.21.m.1.cv1.conv.weight\", \"model.model.21.m.1.cv1.conv.bias\", \"model.model.21.m.1.cv1.conv._input_quantizer._amax\", \"model.model.21.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.21.m.1.cv2.conv.weight\", \"model.model.21.m.1.cv2.conv.bias\", \"model.model.21.m.1.cv2.conv._input_quantizer._amax\", \"model.model.21.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.21.m.0.cv1.conv.bias\", \"model.model.21.m.0.cv1.conv._input_quantizer._amax\", \"model.model.21.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.21.m.0.cv2.conv.bias\", \"model.model.21.m.0.cv2.conv._input_quantizer._amax\", \"model.model.21.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.22.cv2.0.0.conv.bias\", \"model.model.22.cv2.0.0.conv._input_quantizer._amax\", \"model.model.22.cv2.0.0.conv._weight_quantizer._amax\", \"model.model.22.cv2.0.1.conv.bias\", \"model.model.22.cv2.0.1.conv._input_quantizer._amax\", \"model.model.22.cv2.0.1.conv._weight_quantizer._amax\", \"model.model.22.cv2.0.2._input_quantizer._amax\", \"model.model.22.cv2.0.2._weight_quantizer._amax\", \"model.model.22.cv2.1.0.conv.bias\", \"model.model.22.cv2.1.0.conv._input_quantizer._amax\", \"model.model.22.cv2.1.0.conv._weight_quantizer._amax\", \"model.model.22.cv2.1.1.conv.bias\", \"model.model.22.cv2.1.1.conv._input_quantizer._amax\", \"model.model.22.cv2.1.1.conv._weight_quantizer._amax\", \"model.model.22.cv2.1.2._input_quantizer._amax\", \"model.model.22.cv2.1.2._weight_quantizer._amax\", \"model.model.22.cv2.2.0.conv.bias\", \"model.model.22.cv2.2.0.conv._input_quantizer._amax\", \"model.model.22.cv2.2.0.conv._weight_quantizer._amax\", \"model.model.22.cv2.2.1.conv.bias\", \"model.model.22.cv2.2.1.conv._input_quantizer._amax\", \"model.model.22.cv2.2.1.conv._weight_quantizer._amax\", \"model.model.22.cv2.2.2._input_quantizer._amax\", \"model.model.22.cv2.2.2._weight_quantizer._amax\", \"model.model.22.cv3.0.0.conv.bias\", \"model.model.22.cv3.0.0.conv._input_quantizer._amax\", \"model.model.22.cv3.0.0.conv._weight_quantizer._amax\", \"model.model.22.cv3.0.1.conv.bias\", \"model.model.22.cv3.0.1.conv._input_quantizer._amax\", \"model.model.22.cv3.0.1.conv._weight_quantizer._amax\", \"model.model.22.cv3.0.2._input_quantizer._amax\", \"model.model.22.cv3.0.2._weight_quantizer._amax\", \"model.model.22.cv3.1.0.conv.bias\", \"model.model.22.cv3.1.0.conv._input_quantizer._amax\", \"model.model.22.cv3.1.0.conv._weight_quantizer._amax\", \"model.model.22.cv3.1.1.conv.bias\", \"model.model.22.cv3.1.1.conv._input_quantizer._amax\", \"model.model.22.cv3.1.1.conv._weight_quantizer._amax\", \"model.model.22.cv3.1.2._input_quantizer._amax\", \"model.model.22.cv3.1.2._weight_quantizer._amax\", \"model.model.22.cv3.2.0.conv.bias\", \"model.model.22.cv3.2.0.conv._input_quantizer._amax\", \"model.model.22.cv3.2.0.conv._weight_quantizer._amax\", \"model.model.22.cv3.2.1.conv.bias\", \"model.model.22.cv3.2.1.conv._input_quantizer._amax\", \"model.model.22.cv3.2.1.conv._weight_quantizer._amax\", \"model.model.22.cv3.2.2._input_quantizer._amax\", \"model.model.22.cv3.2.2._weight_quantizer._amax\", \"model.model.22.dfl.conv._input_quantizer._amax\", \"model.model.22.dfl.conv._weight_quantizer._amax\". \n\tsize mismatch for model.model.0.conv.weight: copying a param with shape torch.Size([48, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).\n\tsize mismatch for model.model.1.conv.weight: copying a param with shape torch.Size([96, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).\n\tsize mismatch for model.model.2.cv1.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).\n\tsize mismatch for model.model.2.cv2.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 48, 1, 1]).\n\tsize mismatch for model.model.2.m.0.cv1.conv.weight: copying a param with shape torch.Size([48, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for model.model.2.m.0.cv2.conv.weight: copying a param with shape torch.Size([48, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for model.model.3.conv.weight: copying a param with shape torch.Size([192, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for model.model.4.cv1.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for model.model.4.cv2.conv.weight: copying a param with shape torch.Size([192, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for model.model.4.m.0.cv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.4.m.0.cv2.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.4.m.1.cv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.4.m.1.cv2.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.5.conv.weight: copying a param with shape torch.Size([384, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for model.model.6.cv1.conv.weight: copying a param with shape torch.Size([384, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for model.model.6.cv2.conv.weight: copying a param with shape torch.Size([384, 1152, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for model.model.6.m.0.cv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.6.m.0.cv2.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.6.m.1.cv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.6.m.1.cv2.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.7.conv.weight: copying a param with shape torch.Size([576, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for model.model.8.cv1.conv.weight: copying a param with shape torch.Size([576, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for model.model.8.cv2.conv.weight: copying a param with shape torch.Size([576, 1152, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for model.model.8.m.0.cv1.conv.weight: copying a param with shape torch.Size([288, 288, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.model.8.m.0.cv2.conv.weight: copying a param with shape torch.Size([288, 288, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.model.9.cv1.conv.weight: copying a param with shape torch.Size([288, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for model.model.9.cv2.conv.weight: copying a param with shape torch.Size([576, 1152, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for model.model.12.cv1.conv.weight: copying a param with shape torch.Size([384, 960, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 384, 1, 1]).\n\tsize mismatch for model.model.12.cv2.conv.weight: copying a param with shape torch.Size([384, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n\tsize mismatch for model.model.12.m.0.cv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.12.m.0.cv2.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.15.cv1.conv.weight: copying a param with shape torch.Size([192, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 192, 1, 1]).\n\tsize mismatch for model.model.15.cv2.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 96, 1, 1]).\n\tsize mismatch for model.model.15.m.0.cv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.15.m.0.cv2.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.16.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.18.cv1.conv.weight: copying a param with shape torch.Size([384, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n\tsize mismatch for model.model.18.cv2.conv.weight: copying a param with shape torch.Size([384, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n\tsize mismatch for model.model.18.m.0.cv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.18.m.0.cv2.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.19.conv.weight: copying a param with shape torch.Size([384, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.model.21.cv1.conv.weight: copying a param with shape torch.Size([576, 960, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for model.model.21.cv2.conv.weight: copying a param with shape torch.Size([576, 1152, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for model.model.21.m.0.cv1.conv.weight: copying a param with shape torch.Size([288, 288, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.model.21.m.0.cv2.conv.weight: copying a param with shape torch.Size([288, 288, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.model.22.cv2.0.0.conv.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.22.cv2.1.0.conv.weight: copying a param with shape torch.Size([64, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\n\tsize mismatch for model.model.22.cv2.2.0.conv.weight: copying a param with shape torch.Size([64, 576, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 3, 3]).\n\tsize mismatch for model.model.22.cv3.0.0.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 64, 3, 3]).\n\tsize mismatch for model.model.22.cv3.0.1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for model.model.22.cv3.0.2.weight: copying a param with shape torch.Size([80, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 80, 1, 1]).\n\tsize mismatch for model.model.22.cv3.1.0.conv.weight: copying a param with shape torch.Size([192, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 128, 3, 3]).\n\tsize mismatch for model.model.22.cv3.1.1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for model.model.22.cv3.1.2.weight: copying a param with shape torch.Size([80, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 80, 1, 1]).\n\tsize mismatch for model.model.22.cv3.2.0.conv.weight: copying a param with shape torch.Size([192, 576, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 256, 3, 3]).\n\tsize mismatch for model.model.22.cv3.2.1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for model.model.22.cv3.2.2.weight: copying a param with shape torch.Size([80, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 80, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mquant_05271800-calibrated.pth\u001b[39m\u001b[39m\"\u001b[39m, map_location\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m model\u001b[39m=\u001b[39mYOLO()\n\u001b[0;32m----> 6\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(state_dict)\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2185\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2186\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2189\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2190\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2191\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for YOLO:\n\tMissing key(s) in state_dict: \"model.model.0.bn.weight\", \"model.model.0.bn.bias\", \"model.model.0.bn.running_mean\", \"model.model.0.bn.running_var\", \"model.model.1.bn.weight\", \"model.model.1.bn.bias\", \"model.model.1.bn.running_mean\", \"model.model.1.bn.running_var\", \"model.model.2.cv1.bn.weight\", \"model.model.2.cv1.bn.bias\", \"model.model.2.cv1.bn.running_mean\", \"model.model.2.cv1.bn.running_var\", \"model.model.2.cv2.bn.weight\", \"model.model.2.cv2.bn.bias\", \"model.model.2.cv2.bn.running_mean\", \"model.model.2.cv2.bn.running_var\", \"model.model.2.m.0.cv1.bn.weight\", \"model.model.2.m.0.cv1.bn.bias\", \"model.model.2.m.0.cv1.bn.running_mean\", \"model.model.2.m.0.cv1.bn.running_var\", \"model.model.2.m.0.cv2.bn.weight\", \"model.model.2.m.0.cv2.bn.bias\", \"model.model.2.m.0.cv2.bn.running_mean\", \"model.model.2.m.0.cv2.bn.running_var\", \"model.model.3.bn.weight\", \"model.model.3.bn.bias\", \"model.model.3.bn.running_mean\", \"model.model.3.bn.running_var\", \"model.model.4.cv1.bn.weight\", \"model.model.4.cv1.bn.bias\", \"model.model.4.cv1.bn.running_mean\", \"model.model.4.cv1.bn.running_var\", \"model.model.4.cv2.bn.weight\", \"model.model.4.cv2.bn.bias\", \"model.model.4.cv2.bn.running_mean\", \"model.model.4.cv2.bn.running_var\", \"model.model.4.m.0.cv1.bn.weight\", \"model.model.4.m.0.cv1.bn.bias\", \"model.model.4.m.0.cv1.bn.running_mean\", \"model.model.4.m.0.cv1.bn.running_var\", \"model.model.4.m.0.cv2.bn.weight\", \"model.model.4.m.0.cv2.bn.bias\", \"model.model.4.m.0.cv2.bn.running_mean\", \"model.model.4.m.0.cv2.bn.running_var\", \"model.model.4.m.1.cv1.bn.weight\", \"model.model.4.m.1.cv1.bn.bias\", \"model.model.4.m.1.cv1.bn.running_mean\", \"model.model.4.m.1.cv1.bn.running_var\", \"model.model.4.m.1.cv2.bn.weight\", \"model.model.4.m.1.cv2.bn.bias\", \"model.model.4.m.1.cv2.bn.running_mean\", \"model.model.4.m.1.cv2.bn.running_var\", \"model.model.5.bn.weight\", \"model.model.5.bn.bias\", \"model.model.5.bn.running_mean\", \"model.model.5.bn.running_var\", \"model.model.6.cv1.bn.weight\", \"model.model.6.cv1.bn.bias\", \"model.model.6.cv1.bn.running_mean\", \"model.model.6.cv1.bn.running_var\", \"model.model.6.cv2.bn.weight\", \"model.model.6.cv2.bn.bias\", \"model.model.6.cv2.bn.running_mean\", \"model.model.6.cv2.bn.running_var\", \"model.model.6.m.0.cv1.bn.weight\", \"model.model.6.m.0.cv1.bn.bias\", \"model.model.6.m.0.cv1.bn.running_mean\", \"model.model.6.m.0.cv1.bn.running_var\", \"model.model.6.m.0.cv2.bn.weight\", \"model.model.6.m.0.cv2.bn.bias\", \"model.model.6.m.0.cv2.bn.running_mean\", \"model.model.6.m.0.cv2.bn.running_var\", \"model.model.6.m.1.cv1.bn.weight\", \"model.model.6.m.1.cv1.bn.bias\", \"model.model.6.m.1.cv1.bn.running_mean\", \"model.model.6.m.1.cv1.bn.running_var\", \"model.model.6.m.1.cv2.bn.weight\", \"model.model.6.m.1.cv2.bn.bias\", \"model.model.6.m.1.cv2.bn.running_mean\", \"model.model.6.m.1.cv2.bn.running_var\", \"model.model.7.bn.weight\", \"model.model.7.bn.bias\", \"model.model.7.bn.running_mean\", \"model.model.7.bn.running_var\", \"model.model.8.cv1.bn.weight\", \"model.model.8.cv1.bn.bias\", \"model.model.8.cv1.bn.running_mean\", \"model.model.8.cv1.bn.running_var\", \"model.model.8.cv2.bn.weight\", \"model.model.8.cv2.bn.bias\", \"model.model.8.cv2.bn.running_mean\", \"model.model.8.cv2.bn.running_var\", \"model.model.8.m.0.cv1.bn.weight\", \"model.model.8.m.0.cv1.bn.bias\", \"model.model.8.m.0.cv1.bn.running_mean\", \"model.model.8.m.0.cv1.bn.running_var\", \"model.model.8.m.0.cv2.bn.weight\", \"model.model.8.m.0.cv2.bn.bias\", \"model.model.8.m.0.cv2.bn.running_mean\", \"model.model.8.m.0.cv2.bn.running_var\", \"model.model.9.cv1.bn.weight\", \"model.model.9.cv1.bn.bias\", \"model.model.9.cv1.bn.running_mean\", \"model.model.9.cv1.bn.running_var\", \"model.model.9.cv2.bn.weight\", \"model.model.9.cv2.bn.bias\", \"model.model.9.cv2.bn.running_mean\", \"model.model.9.cv2.bn.running_var\", \"model.model.12.cv1.bn.weight\", \"model.model.12.cv1.bn.bias\", \"model.model.12.cv1.bn.running_mean\", \"model.model.12.cv1.bn.running_var\", \"model.model.12.cv2.bn.weight\", \"model.model.12.cv2.bn.bias\", \"model.model.12.cv2.bn.running_mean\", \"model.model.12.cv2.bn.running_var\", \"model.model.12.m.0.cv1.bn.weight\", \"model.model.12.m.0.cv1.bn.bias\", \"model.model.12.m.0.cv1.bn.running_mean\", \"model.model.12.m.0.cv1.bn.running_var\", \"model.model.12.m.0.cv2.bn.weight\", \"model.model.12.m.0.cv2.bn.bias\", \"model.model.12.m.0.cv2.bn.running_mean\", \"model.model.12.m.0.cv2.bn.running_var\", \"model.model.15.cv1.bn.weight\", \"model.model.15.cv1.bn.bias\", \"model.model.15.cv1.bn.running_mean\", \"model.model.15.cv1.bn.running_var\", \"model.model.15.cv2.bn.weight\", \"model.model.15.cv2.bn.bias\", \"model.model.15.cv2.bn.running_mean\", \"model.model.15.cv2.bn.running_var\", \"model.model.15.m.0.cv1.bn.weight\", \"model.model.15.m.0.cv1.bn.bias\", \"model.model.15.m.0.cv1.bn.running_mean\", \"model.model.15.m.0.cv1.bn.running_var\", \"model.model.15.m.0.cv2.bn.weight\", \"model.model.15.m.0.cv2.bn.bias\", \"model.model.15.m.0.cv2.bn.running_mean\", \"model.model.15.m.0.cv2.bn.running_var\", \"model.model.16.bn.weight\", \"model.model.16.bn.bias\", \"model.model.16.bn.running_mean\", \"model.model.16.bn.running_var\", \"model.model.18.cv1.bn.weight\", \"model.model.18.cv1.bn.bias\", \"model.model.18.cv1.bn.running_mean\", \"model.model.18.cv1.bn.running_var\", \"model.model.18.cv2.bn.weight\", \"model.model.18.cv2.bn.bias\", \"model.model.18.cv2.bn.running_mean\", \"model.model.18.cv2.bn.running_var\", \"model.model.18.m.0.cv1.bn.weight\", \"model.model.18.m.0.cv1.bn.bias\", \"model.model.18.m.0.cv1.bn.running_mean\", \"model.model.18.m.0.cv1.bn.running_var\", \"model.model.18.m.0.cv2.bn.weight\", \"model.model.18.m.0.cv2.bn.bias\", \"model.model.18.m.0.cv2.bn.running_mean\", \"model.model.18.m.0.cv2.bn.running_var\", \"model.model.19.bn.weight\", \"model.model.19.bn.bias\", \"model.model.19.bn.running_mean\", \"model.model.19.bn.running_var\", \"model.model.21.cv1.bn.weight\", \"model.model.21.cv1.bn.bias\", \"model.model.21.cv1.bn.running_mean\", \"model.model.21.cv1.bn.running_var\", \"model.model.21.cv2.bn.weight\", \"model.model.21.cv2.bn.bias\", \"model.model.21.cv2.bn.running_mean\", \"model.model.21.cv2.bn.running_var\", \"model.model.21.m.0.cv1.bn.weight\", \"model.model.21.m.0.cv1.bn.bias\", \"model.model.21.m.0.cv1.bn.running_mean\", \"model.model.21.m.0.cv1.bn.running_var\", \"model.model.21.m.0.cv2.bn.weight\", \"model.model.21.m.0.cv2.bn.bias\", \"model.model.21.m.0.cv2.bn.running_mean\", \"model.model.21.m.0.cv2.bn.running_var\", \"model.model.22.cv2.0.0.bn.weight\", \"model.model.22.cv2.0.0.bn.bias\", \"model.model.22.cv2.0.0.bn.running_mean\", \"model.model.22.cv2.0.0.bn.running_var\", \"model.model.22.cv2.0.1.bn.weight\", \"model.model.22.cv2.0.1.bn.bias\", \"model.model.22.cv2.0.1.bn.running_mean\", \"model.model.22.cv2.0.1.bn.running_var\", \"model.model.22.cv2.1.0.bn.weight\", \"model.model.22.cv2.1.0.bn.bias\", \"model.model.22.cv2.1.0.bn.running_mean\", \"model.model.22.cv2.1.0.bn.running_var\", \"model.model.22.cv2.1.1.bn.weight\", \"model.model.22.cv2.1.1.bn.bias\", \"model.model.22.cv2.1.1.bn.running_mean\", \"model.model.22.cv2.1.1.bn.running_var\", \"model.model.22.cv2.2.0.bn.weight\", \"model.model.22.cv2.2.0.bn.bias\", \"model.model.22.cv2.2.0.bn.running_mean\", \"model.model.22.cv2.2.0.bn.running_var\", \"model.model.22.cv2.2.1.bn.weight\", \"model.model.22.cv2.2.1.bn.bias\", \"model.model.22.cv2.2.1.bn.running_mean\", \"model.model.22.cv2.2.1.bn.running_var\", \"model.model.22.cv3.0.0.bn.weight\", \"model.model.22.cv3.0.0.bn.bias\", \"model.model.22.cv3.0.0.bn.running_mean\", \"model.model.22.cv3.0.0.bn.running_var\", \"model.model.22.cv3.0.1.bn.weight\", \"model.model.22.cv3.0.1.bn.bias\", \"model.model.22.cv3.0.1.bn.running_mean\", \"model.model.22.cv3.0.1.bn.running_var\", \"model.model.22.cv3.1.0.bn.weight\", \"model.model.22.cv3.1.0.bn.bias\", \"model.model.22.cv3.1.0.bn.running_mean\", \"model.model.22.cv3.1.0.bn.running_var\", \"model.model.22.cv3.1.1.bn.weight\", \"model.model.22.cv3.1.1.bn.bias\", \"model.model.22.cv3.1.1.bn.running_mean\", \"model.model.22.cv3.1.1.bn.running_var\", \"model.model.22.cv3.2.0.bn.weight\", \"model.model.22.cv3.2.0.bn.bias\", \"model.model.22.cv3.2.0.bn.running_mean\", \"model.model.22.cv3.2.0.bn.running_var\", \"model.model.22.cv3.2.1.bn.weight\", \"model.model.22.cv3.2.1.bn.bias\", \"model.model.22.cv3.2.1.bn.running_mean\", \"model.model.22.cv3.2.1.bn.running_var\". \n\tUnexpected key(s) in state_dict: \"model.model.0.conv.bias\", \"model.model.0.conv._input_quantizer._amax\", \"model.model.0.conv._weight_quantizer._amax\", \"model.model.1.conv.bias\", \"model.model.1.conv._input_quantizer._amax\", \"model.model.1.conv._weight_quantizer._amax\", \"model.model.2.c2fchunkop._input0_quantizer._amax\", \"model.model.2.cv1.conv.bias\", \"model.model.2.cv1.conv._input_quantizer._amax\", \"model.model.2.cv1.conv._weight_quantizer._amax\", \"model.model.2.cv2.conv.bias\", \"model.model.2.cv2.conv._input_quantizer._amax\", \"model.model.2.cv2.conv._weight_quantizer._amax\", \"model.model.2.m.1.cv1.conv.weight\", \"model.model.2.m.1.cv1.conv.bias\", \"model.model.2.m.1.cv1.conv._input_quantizer._amax\", \"model.model.2.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.2.m.1.cv2.conv.weight\", \"model.model.2.m.1.cv2.conv.bias\", \"model.model.2.m.1.cv2.conv._input_quantizer._amax\", \"model.model.2.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.2.m.1.addop._input0_quantizer._amax\", \"model.model.2.m.1.addop._input1_quantizer._amax\", \"model.model.2.m.0.addop._input0_quantizer._amax\", \"model.model.2.m.0.addop._input1_quantizer._amax\", \"model.model.2.m.0.cv1.conv.bias\", \"model.model.2.m.0.cv1.conv._input_quantizer._amax\", \"model.model.2.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.2.m.0.cv2.conv.bias\", \"model.model.2.m.0.cv2.conv._input_quantizer._amax\", \"model.model.2.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.3.conv.bias\", \"model.model.3.conv._input_quantizer._amax\", \"model.model.3.conv._weight_quantizer._amax\", \"model.model.4.c2fchunkop._input0_quantizer._amax\", \"model.model.4.cv1.conv.bias\", \"model.model.4.cv1.conv._input_quantizer._amax\", \"model.model.4.cv1.conv._weight_quantizer._amax\", \"model.model.4.cv2.conv.bias\", \"model.model.4.cv2.conv._input_quantizer._amax\", \"model.model.4.cv2.conv._weight_quantizer._amax\", \"model.model.4.m.2.cv1.conv.weight\", \"model.model.4.m.2.cv1.conv.bias\", \"model.model.4.m.2.cv1.conv._input_quantizer._amax\", \"model.model.4.m.2.cv1.conv._weight_quantizer._amax\", \"model.model.4.m.2.cv2.conv.weight\", \"model.model.4.m.2.cv2.conv.bias\", \"model.model.4.m.2.cv2.conv._input_quantizer._amax\", \"model.model.4.m.2.cv2.conv._weight_quantizer._amax\", \"model.model.4.m.2.addop._input0_quantizer._amax\", \"model.model.4.m.2.addop._input1_quantizer._amax\", \"model.model.4.m.3.cv1.conv.weight\", \"model.model.4.m.3.cv1.conv.bias\", \"model.model.4.m.3.cv1.conv._input_quantizer._amax\", \"model.model.4.m.3.cv1.conv._weight_quantizer._amax\", \"model.model.4.m.3.cv2.conv.weight\", \"model.model.4.m.3.cv2.conv.bias\", \"model.model.4.m.3.cv2.conv._input_quantizer._amax\", \"model.model.4.m.3.cv2.conv._weight_quantizer._amax\", \"model.model.4.m.3.addop._input0_quantizer._amax\", \"model.model.4.m.3.addop._input1_quantizer._amax\", \"model.model.4.m.0.addop._input0_quantizer._amax\", \"model.model.4.m.0.addop._input1_quantizer._amax\", \"model.model.4.m.0.cv1.conv.bias\", \"model.model.4.m.0.cv1.conv._input_quantizer._amax\", \"model.model.4.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.4.m.0.cv2.conv.bias\", \"model.model.4.m.0.cv2.conv._input_quantizer._amax\", \"model.model.4.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.4.m.1.addop._input0_quantizer._amax\", \"model.model.4.m.1.addop._input1_quantizer._amax\", \"model.model.4.m.1.cv1.conv.bias\", \"model.model.4.m.1.cv1.conv._input_quantizer._amax\", \"model.model.4.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.4.m.1.cv2.conv.bias\", \"model.model.4.m.1.cv2.conv._input_quantizer._amax\", \"model.model.4.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.5.conv.bias\", \"model.model.5.conv._input_quantizer._amax\", \"model.model.5.conv._weight_quantizer._amax\", \"model.model.6.c2fchunkop._input0_quantizer._amax\", \"model.model.6.cv1.conv.bias\", \"model.model.6.cv1.conv._input_quantizer._amax\", \"model.model.6.cv1.conv._weight_quantizer._amax\", \"model.model.6.cv2.conv.bias\", \"model.model.6.cv2.conv._input_quantizer._amax\", \"model.model.6.cv2.conv._weight_quantizer._amax\", \"model.model.6.m.2.cv1.conv.weight\", \"model.model.6.m.2.cv1.conv.bias\", \"model.model.6.m.2.cv1.conv._input_quantizer._amax\", \"model.model.6.m.2.cv1.conv._weight_quantizer._amax\", \"model.model.6.m.2.cv2.conv.weight\", \"model.model.6.m.2.cv2.conv.bias\", \"model.model.6.m.2.cv2.conv._input_quantizer._amax\", \"model.model.6.m.2.cv2.conv._weight_quantizer._amax\", \"model.model.6.m.2.addop._input0_quantizer._amax\", \"model.model.6.m.2.addop._input1_quantizer._amax\", \"model.model.6.m.3.cv1.conv.weight\", \"model.model.6.m.3.cv1.conv.bias\", \"model.model.6.m.3.cv1.conv._input_quantizer._amax\", \"model.model.6.m.3.cv1.conv._weight_quantizer._amax\", \"model.model.6.m.3.cv2.conv.weight\", \"model.model.6.m.3.cv2.conv.bias\", \"model.model.6.m.3.cv2.conv._input_quantizer._amax\", \"model.model.6.m.3.cv2.conv._weight_quantizer._amax\", \"model.model.6.m.3.addop._input0_quantizer._amax\", \"model.model.6.m.3.addop._input1_quantizer._amax\", \"model.model.6.m.0.addop._input0_quantizer._amax\", \"model.model.6.m.0.addop._input1_quantizer._amax\", \"model.model.6.m.0.cv1.conv.bias\", \"model.model.6.m.0.cv1.conv._input_quantizer._amax\", \"model.model.6.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.6.m.0.cv2.conv.bias\", \"model.model.6.m.0.cv2.conv._input_quantizer._amax\", \"model.model.6.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.6.m.1.addop._input0_quantizer._amax\", \"model.model.6.m.1.addop._input1_quantizer._amax\", \"model.model.6.m.1.cv1.conv.bias\", \"model.model.6.m.1.cv1.conv._input_quantizer._amax\", \"model.model.6.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.6.m.1.cv2.conv.bias\", \"model.model.6.m.1.cv2.conv._input_quantizer._amax\", \"model.model.6.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.7.conv.bias\", \"model.model.7.conv._input_quantizer._amax\", \"model.model.7.conv._weight_quantizer._amax\", \"model.model.8.c2fchunkop._input0_quantizer._amax\", \"model.model.8.cv1.conv.bias\", \"model.model.8.cv1.conv._input_quantizer._amax\", \"model.model.8.cv1.conv._weight_quantizer._amax\", \"model.model.8.cv2.conv.bias\", \"model.model.8.cv2.conv._input_quantizer._amax\", \"model.model.8.cv2.conv._weight_quantizer._amax\", \"model.model.8.m.1.cv1.conv.weight\", \"model.model.8.m.1.cv1.conv.bias\", \"model.model.8.m.1.cv1.conv._input_quantizer._amax\", \"model.model.8.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.8.m.1.cv2.conv.weight\", \"model.model.8.m.1.cv2.conv.bias\", \"model.model.8.m.1.cv2.conv._input_quantizer._amax\", \"model.model.8.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.8.m.1.addop._input0_quantizer._amax\", \"model.model.8.m.1.addop._input1_quantizer._amax\", \"model.model.8.m.0.addop._input0_quantizer._amax\", \"model.model.8.m.0.addop._input1_quantizer._amax\", \"model.model.8.m.0.cv1.conv.bias\", \"model.model.8.m.0.cv1.conv._input_quantizer._amax\", \"model.model.8.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.8.m.0.cv2.conv.bias\", \"model.model.8.m.0.cv2.conv._input_quantizer._amax\", \"model.model.8.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.9.cv1.conv.bias\", \"model.model.9.cv1.conv._input_quantizer._amax\", \"model.model.9.cv1.conv._weight_quantizer._amax\", \"model.model.9.cv2.conv.bias\", \"model.model.9.cv2.conv._input_quantizer._amax\", \"model.model.9.cv2.conv._weight_quantizer._amax\", \"model.model.10.upsampleop._input_quantizer._amax\", \"model.model.11.concatop._input0_quantizer._amax\", \"model.model.11.concatop._input1_quantizer._amax\", \"model.model.12.c2fchunkop._input0_quantizer._amax\", \"model.model.12.cv1.conv.bias\", \"model.model.12.cv1.conv._input_quantizer._amax\", \"model.model.12.cv1.conv._weight_quantizer._amax\", \"model.model.12.cv2.conv.bias\", \"model.model.12.cv2.conv._input_quantizer._amax\", \"model.model.12.cv2.conv._weight_quantizer._amax\", \"model.model.12.m.1.cv1.conv.weight\", \"model.model.12.m.1.cv1.conv.bias\", \"model.model.12.m.1.cv1.conv._input_quantizer._amax\", \"model.model.12.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.12.m.1.cv2.conv.weight\", \"model.model.12.m.1.cv2.conv.bias\", \"model.model.12.m.1.cv2.conv._input_quantizer._amax\", \"model.model.12.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.12.m.0.cv1.conv.bias\", \"model.model.12.m.0.cv1.conv._input_quantizer._amax\", \"model.model.12.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.12.m.0.cv2.conv.bias\", \"model.model.12.m.0.cv2.conv._input_quantizer._amax\", \"model.model.12.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.13.upsampleop._input_quantizer._amax\", \"model.model.14.concatop._input0_quantizer._amax\", \"model.model.14.concatop._input1_quantizer._amax\", \"model.model.15.c2fchunkop._input0_quantizer._amax\", \"model.model.15.cv1.conv.bias\", \"model.model.15.cv1.conv._input_quantizer._amax\", \"model.model.15.cv1.conv._weight_quantizer._amax\", \"model.model.15.cv2.conv.bias\", \"model.model.15.cv2.conv._input_quantizer._amax\", \"model.model.15.cv2.conv._weight_quantizer._amax\", \"model.model.15.m.1.cv1.conv.weight\", \"model.model.15.m.1.cv1.conv.bias\", \"model.model.15.m.1.cv1.conv._input_quantizer._amax\", \"model.model.15.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.15.m.1.cv2.conv.weight\", \"model.model.15.m.1.cv2.conv.bias\", \"model.model.15.m.1.cv2.conv._input_quantizer._amax\", \"model.model.15.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.15.m.0.cv1.conv.bias\", \"model.model.15.m.0.cv1.conv._input_quantizer._amax\", \"model.model.15.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.15.m.0.cv2.conv.bias\", \"model.model.15.m.0.cv2.conv._input_quantizer._amax\", \"model.model.15.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.16.conv.bias\", \"model.model.16.conv._input_quantizer._amax\", \"model.model.16.conv._weight_quantizer._amax\", \"model.model.17.concatop._input0_quantizer._amax\", \"model.model.17.concatop._input1_quantizer._amax\", \"model.model.18.c2fchunkop._input0_quantizer._amax\", \"model.model.18.cv1.conv.bias\", \"model.model.18.cv1.conv._input_quantizer._amax\", \"model.model.18.cv1.conv._weight_quantizer._amax\", \"model.model.18.cv2.conv.bias\", \"model.model.18.cv2.conv._input_quantizer._amax\", \"model.model.18.cv2.conv._weight_quantizer._amax\", \"model.model.18.m.1.cv1.conv.weight\", \"model.model.18.m.1.cv1.conv.bias\", \"model.model.18.m.1.cv1.conv._input_quantizer._amax\", \"model.model.18.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.18.m.1.cv2.conv.weight\", \"model.model.18.m.1.cv2.conv.bias\", \"model.model.18.m.1.cv2.conv._input_quantizer._amax\", \"model.model.18.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.18.m.0.cv1.conv.bias\", \"model.model.18.m.0.cv1.conv._input_quantizer._amax\", \"model.model.18.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.18.m.0.cv2.conv.bias\", \"model.model.18.m.0.cv2.conv._input_quantizer._amax\", \"model.model.18.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.19.conv.bias\", \"model.model.19.conv._input_quantizer._amax\", \"model.model.19.conv._weight_quantizer._amax\", \"model.model.20.concatop._input0_quantizer._amax\", \"model.model.20.concatop._input1_quantizer._amax\", \"model.model.21.c2fchunkop._input0_quantizer._amax\", \"model.model.21.cv1.conv.bias\", \"model.model.21.cv1.conv._input_quantizer._amax\", \"model.model.21.cv1.conv._weight_quantizer._amax\", \"model.model.21.cv2.conv.bias\", \"model.model.21.cv2.conv._input_quantizer._amax\", \"model.model.21.cv2.conv._weight_quantizer._amax\", \"model.model.21.m.1.cv1.conv.weight\", \"model.model.21.m.1.cv1.conv.bias\", \"model.model.21.m.1.cv1.conv._input_quantizer._amax\", \"model.model.21.m.1.cv1.conv._weight_quantizer._amax\", \"model.model.21.m.1.cv2.conv.weight\", \"model.model.21.m.1.cv2.conv.bias\", \"model.model.21.m.1.cv2.conv._input_quantizer._amax\", \"model.model.21.m.1.cv2.conv._weight_quantizer._amax\", \"model.model.21.m.0.cv1.conv.bias\", \"model.model.21.m.0.cv1.conv._input_quantizer._amax\", \"model.model.21.m.0.cv1.conv._weight_quantizer._amax\", \"model.model.21.m.0.cv2.conv.bias\", \"model.model.21.m.0.cv2.conv._input_quantizer._amax\", \"model.model.21.m.0.cv2.conv._weight_quantizer._amax\", \"model.model.22.cv2.0.0.conv.bias\", \"model.model.22.cv2.0.0.conv._input_quantizer._amax\", \"model.model.22.cv2.0.0.conv._weight_quantizer._amax\", \"model.model.22.cv2.0.1.conv.bias\", \"model.model.22.cv2.0.1.conv._input_quantizer._amax\", \"model.model.22.cv2.0.1.conv._weight_quantizer._amax\", \"model.model.22.cv2.0.2._input_quantizer._amax\", \"model.model.22.cv2.0.2._weight_quantizer._amax\", \"model.model.22.cv2.1.0.conv.bias\", \"model.model.22.cv2.1.0.conv._input_quantizer._amax\", \"model.model.22.cv2.1.0.conv._weight_quantizer._amax\", \"model.model.22.cv2.1.1.conv.bias\", \"model.model.22.cv2.1.1.conv._input_quantizer._amax\", \"model.model.22.cv2.1.1.conv._weight_quantizer._amax\", \"model.model.22.cv2.1.2._input_quantizer._amax\", \"model.model.22.cv2.1.2._weight_quantizer._amax\", \"model.model.22.cv2.2.0.conv.bias\", \"model.model.22.cv2.2.0.conv._input_quantizer._amax\", \"model.model.22.cv2.2.0.conv._weight_quantizer._amax\", \"model.model.22.cv2.2.1.conv.bias\", \"model.model.22.cv2.2.1.conv._input_quantizer._amax\", \"model.model.22.cv2.2.1.conv._weight_quantizer._amax\", \"model.model.22.cv2.2.2._input_quantizer._amax\", \"model.model.22.cv2.2.2._weight_quantizer._amax\", \"model.model.22.cv3.0.0.conv.bias\", \"model.model.22.cv3.0.0.conv._input_quantizer._amax\", \"model.model.22.cv3.0.0.conv._weight_quantizer._amax\", \"model.model.22.cv3.0.1.conv.bias\", \"model.model.22.cv3.0.1.conv._input_quantizer._amax\", \"model.model.22.cv3.0.1.conv._weight_quantizer._amax\", \"model.model.22.cv3.0.2._input_quantizer._amax\", \"model.model.22.cv3.0.2._weight_quantizer._amax\", \"model.model.22.cv3.1.0.conv.bias\", \"model.model.22.cv3.1.0.conv._input_quantizer._amax\", \"model.model.22.cv3.1.0.conv._weight_quantizer._amax\", \"model.model.22.cv3.1.1.conv.bias\", \"model.model.22.cv3.1.1.conv._input_quantizer._amax\", \"model.model.22.cv3.1.1.conv._weight_quantizer._amax\", \"model.model.22.cv3.1.2._input_quantizer._amax\", \"model.model.22.cv3.1.2._weight_quantizer._amax\", \"model.model.22.cv3.2.0.conv.bias\", \"model.model.22.cv3.2.0.conv._input_quantizer._amax\", \"model.model.22.cv3.2.0.conv._weight_quantizer._amax\", \"model.model.22.cv3.2.1.conv.bias\", \"model.model.22.cv3.2.1.conv._input_quantizer._amax\", \"model.model.22.cv3.2.1.conv._weight_quantizer._amax\", \"model.model.22.cv3.2.2._input_quantizer._amax\", \"model.model.22.cv3.2.2._weight_quantizer._amax\", \"model.model.22.dfl.conv._input_quantizer._amax\", \"model.model.22.dfl.conv._weight_quantizer._amax\". \n\tsize mismatch for model.model.0.conv.weight: copying a param with shape torch.Size([48, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).\n\tsize mismatch for model.model.1.conv.weight: copying a param with shape torch.Size([96, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).\n\tsize mismatch for model.model.2.cv1.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).\n\tsize mismatch for model.model.2.cv2.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 48, 1, 1]).\n\tsize mismatch for model.model.2.m.0.cv1.conv.weight: copying a param with shape torch.Size([48, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for model.model.2.m.0.cv2.conv.weight: copying a param with shape torch.Size([48, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for model.model.3.conv.weight: copying a param with shape torch.Size([192, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for model.model.4.cv1.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for model.model.4.cv2.conv.weight: copying a param with shape torch.Size([192, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for model.model.4.m.0.cv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.4.m.0.cv2.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.4.m.1.cv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.4.m.1.cv2.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.5.conv.weight: copying a param with shape torch.Size([384, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for model.model.6.cv1.conv.weight: copying a param with shape torch.Size([384, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for model.model.6.cv2.conv.weight: copying a param with shape torch.Size([384, 1152, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for model.model.6.m.0.cv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.6.m.0.cv2.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.6.m.1.cv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.6.m.1.cv2.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.7.conv.weight: copying a param with shape torch.Size([576, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for model.model.8.cv1.conv.weight: copying a param with shape torch.Size([576, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for model.model.8.cv2.conv.weight: copying a param with shape torch.Size([576, 1152, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for model.model.8.m.0.cv1.conv.weight: copying a param with shape torch.Size([288, 288, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.model.8.m.0.cv2.conv.weight: copying a param with shape torch.Size([288, 288, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.model.9.cv1.conv.weight: copying a param with shape torch.Size([288, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for model.model.9.cv2.conv.weight: copying a param with shape torch.Size([576, 1152, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for model.model.12.cv1.conv.weight: copying a param with shape torch.Size([384, 960, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 384, 1, 1]).\n\tsize mismatch for model.model.12.cv2.conv.weight: copying a param with shape torch.Size([384, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n\tsize mismatch for model.model.12.m.0.cv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.12.m.0.cv2.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.15.cv1.conv.weight: copying a param with shape torch.Size([192, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 192, 1, 1]).\n\tsize mismatch for model.model.15.cv2.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 96, 1, 1]).\n\tsize mismatch for model.model.15.m.0.cv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.15.m.0.cv2.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.model.16.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.18.cv1.conv.weight: copying a param with shape torch.Size([384, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n\tsize mismatch for model.model.18.cv2.conv.weight: copying a param with shape torch.Size([384, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n\tsize mismatch for model.model.18.m.0.cv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.18.m.0.cv2.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.19.conv.weight: copying a param with shape torch.Size([384, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.model.21.cv1.conv.weight: copying a param with shape torch.Size([576, 960, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for model.model.21.cv2.conv.weight: copying a param with shape torch.Size([576, 1152, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for model.model.21.m.0.cv1.conv.weight: copying a param with shape torch.Size([288, 288, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.model.21.m.0.cv2.conv.weight: copying a param with shape torch.Size([288, 288, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for model.model.22.cv2.0.0.conv.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.model.22.cv2.1.0.conv.weight: copying a param with shape torch.Size([64, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\n\tsize mismatch for model.model.22.cv2.2.0.conv.weight: copying a param with shape torch.Size([64, 576, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 3, 3]).\n\tsize mismatch for model.model.22.cv3.0.0.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 64, 3, 3]).\n\tsize mismatch for model.model.22.cv3.0.1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for model.model.22.cv3.0.2.weight: copying a param with shape torch.Size([80, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 80, 1, 1]).\n\tsize mismatch for model.model.22.cv3.1.0.conv.weight: copying a param with shape torch.Size([192, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 128, 3, 3]).\n\tsize mismatch for model.model.22.cv3.1.1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for model.model.22.cv3.1.2.weight: copying a param with shape torch.Size([80, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 80, 1, 1]).\n\tsize mismatch for model.model.22.cv3.2.0.conv.weight: copying a param with shape torch.Size([192, 576, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 256, 3, 3]).\n\tsize mismatch for model.model.22.cv3.2.1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for model.model.22.cv3.2.2.weight: copying a param with shape torch.Size([80, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 80, 1, 1])."
     ]
    }
   ],
   "source": [
    "import pytorch_quantization\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import quant_modules\n",
    "state_dict = torch.load(\"quant_05271800-calibrated.pth\", map_location=\"cpu\")\n",
    "model=YOLO()\n",
    "model.load_state_dict(state_dict)\n",
    "model.cuda()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
